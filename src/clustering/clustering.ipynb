{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8089eed3",
   "metadata": {},
   "source": [
    "# Data Clustering\n",
    "\n",
    "We have high data dimensionality which can be an issue for ease of interpretability. Thus it would be convenient if we could group some features in diffent sub-categories. For example, cluster the genre in several different genre-representative.\n",
    "\n",
    "- actors \n",
    "- characters\n",
    "- genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61140235",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "30eb59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "import re\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f1921",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ba3102",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_pickle(\"../../data/post_processing//country_df.pkl\")\n",
    "comes_from_df = pd.read_pickle(\"../../data/post_processing/comes_from_df.pkl\")\n",
    "genre_df = pd.read_pickle(\"../../data/post_processing/genre_df.pkl\")\n",
    "is_of_type_df = pd.read_pickle(\"../../data/post_processing/is_of_type_df.pkl\")\n",
    "language_df = pd.read_pickle(\"../../data/post_processing/language_df.pkl\")\n",
    "spoken_languages_df = pd.read_pickle(\"../../data/post_processing/spoken_languages_df.pkl\")\n",
    "character_df = pd.read_pickle(\"../../data/post_processing/character_df.pkl\")\n",
    "actor_df = pd.read_pickle(\"../../data/post_processing/actor_df.pkl\")\n",
    "movie_df = pd.read_pickle(\"../../data/post_processing/movie_df.pkl\")\n",
    "belongs_to_df = pd.read_pickle(\"../../data/post_processing/belongs_to_df.pkl\")\n",
    "play_df = pd.read_pickle(\"../../data/post_processing/play_df.pkl\")\n",
    "appears_in_df = pd.read_pickle(\"../../data/post_processing/appears_in_df.pkl\")\n",
    "wikipedia_imdb_mapping_table = pd.read_pickle(\"../../data/generated/wikipedia_imdb_mapping_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591df29b",
   "metadata": {},
   "source": [
    "## Genre Clustering\n",
    "\n",
    "BOW creation Pipeline:\n",
    "- casefolding\n",
    "- remove stopwords\n",
    "- add single words\n",
    "- add bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f81facc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_ID_COL_NAME = \"genre_name\"\n",
    "MOVIE_ID_COL_NAME = \"movie_id\"\n",
    "custom_stopwords = {\"movie\",\"movies\",\"film\",\"films\",\"cinema\",\"&\",\"and\",\"in\",\"of\"}\n",
    "\n",
    "def add_bigrams(words_list: list)-> list:\n",
    "    \"\"\"\n",
    "    Append bigrams to the given words list.\n",
    "    \n",
    "    :param words_list: List words as strings.\n",
    "    \n",
    "    :return: Concatenated lists of both words and bigrams.\n",
    "    \n",
    "    \"\"\"\n",
    "    bigrams = [words_list[i]+\" \"+words_list[i+1] for i in range(len(words_list)-1)]\n",
    "    return words_list+bigrams\n",
    "\n",
    "def process_genre_name(name: str, stop_words: set) -> list:\n",
    "    \"\"\"\n",
    "    Apply basic processing steps to the genre name:\n",
    "        - Casefolding\n",
    "        - Stopwords removal\n",
    "        - Bigram addition\n",
    "        \n",
    "    :param name: String for the genre name\n",
    "    :param stop_words: Set of words considered as stopwords.\n",
    "    \n",
    "    :return: List of processed words and bigrams.\n",
    "    \n",
    "    \"\"\"\n",
    "    words_list = [w.casefold() for w in re.split(\"\\s|/|-\", name) if w not in stop_words]\n",
    "    words_with_bigrams = add_bigrams(words_list)\n",
    "    return words_with_bigrams\n",
    "\n",
    "def generate_vocabulary(genre_dataframe: pd.DataFrame, stop_words: set) -> set:\n",
    "    \"\"\"\n",
    "    Generate the vocabulary out of the given genre DataFrame.\n",
    "    \n",
    "    :param genre_dataframe: Pandas DataFrame containing the data for the genre names.\n",
    "    :param stop_words: Set of words considered as stopwords.\n",
    "    \n",
    "    :return: Set of words and bigrams contained in the vocabulary.\n",
    "    \n",
    "    \"\"\"\n",
    "    genre_name_df = genre_dataframe.reset_index()\n",
    "    genre_name_df[\"words\"] = genre_name_df[GENRE_ID_COL_NAME].apply(\n",
    "            lambda name: process_genre_name(name,stop_words))\n",
    "    vocabulary = set(genre_name_df[\"words\"].aggregate(sum))\n",
    "    return vocabulary\n",
    "\n",
    "def generate_BOW_matrix(movie_genre_dataframe: pd.DataFrame, genre_dataframe: pd.DataFrame,\n",
    "                        stop_words: set) -> tuple:\n",
    "    \"\"\"\n",
    "    Generate the BOW matrix using the following pipeline:\n",
    "        - Process genre names\n",
    "        - Create vocabulary\n",
    "        - Create BOW matrix \n",
    "        \n",
    "    :param movie_genre_dataframe: Pandas DataFrame containing the association between genres and movies.\n",
    "    :param genre_dataframe: Pandas DataFrame containing the data for the genre names.\n",
    "    :param stop_words: Set of words considered as stopwords.\n",
    "    \n",
    "    :return: Return the vocabulary, the ordered list of movie ids for the BOW matrix, and the BOW matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create Vocabulary.\n",
    "    vocabulary = generate_vocabulary(genre_dataframe,stop_words)\n",
    "    # Create one-hot encoding of words for each genre-movie pair.\n",
    "    movie_genre_words_df = movie_genre_dataframe.copy()\n",
    "    movie_genre_words_df[GENRE_ID_COL_NAME] = movie_genre_words_df[GENRE_ID_COL_NAME].apply(\n",
    "            lambda name: process_genre_name(name,stop_words))\n",
    "    movie_genre_words_df[GENRE_ID_COL_NAME] = movie_genre_words_df[GENRE_ID_COL_NAME].apply(\n",
    "            lambda words_list: np.array([1 if w in set(words_list) else 0 for w in list(vocabulary)]))\n",
    "    # Aggregates by summation into a BOW representation the different movies.\n",
    "    grouped_movie_genre_df = movie_genre_words_df.groupby(MOVIE_ID_COL_NAME)[\n",
    "            GENRE_ID_COL_NAME].apply(sum)\n",
    "    grouped_movie_genre_df = grouped_movie_genre_df.sort_index()\n",
    "    # Convert pandas Series to numpy array.\n",
    "    BOW_matrix = grouped_movie_genre_df.reset_index()[GENRE_ID_COL_NAME].agg(\n",
    "        np.concatenate).reshape(len(grouped_movie_genre_df),len(vocabulary))\n",
    "    return vocabulary, grouped_movie_genre_df.index, BOW_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fd046111",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, movie_ids, BOW_matrix = generate_BOW_matrix(is_of_type_df, genre_df, custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e5a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
