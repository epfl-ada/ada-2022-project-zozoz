{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b5181f",
   "metadata": {},
   "source": [
    "# Features Engineering\n",
    "\n",
    "Our data can be very high dimensional if we consider the number of languages, countries, actors etc. We have only 44k movies, but we have several hundreds on genres, languages and countries, which gives already around 10 millions possibilities. And this is without even looking at the hundreds of thousands of actors and characters. Thus we have to come up with features that can capture signal in the data, without having to do one-hot encoding for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07baa4a6",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d253e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# Statistics\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.formula.api as smf\n",
    "# ML models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Sparse Matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import save_npz\n",
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add51810",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4dc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINENT_ID = {\"North America and Australia\": [1,0,0,0,0,0],\n",
    "\"Central and South America\": [0,1,0,0,0,0],\n",
    "\"Western Europe\": [0,0,1,0,0,0],\n",
    "\"Eastern Europe and Russia\": [0,0,0,1,0,0],\n",
    "\"Africa and Middle-East\": [0,0,0,0,1,0],\n",
    "\"Asia\": [0,0,0,0,0,1]}\n",
    "\n",
    "COUNTRY_CONTINENT_MAPPING = {\n",
    "'afghanistan' : \"Africa and Middle-East\",\n",
    " 'albania' : \"Eastern Europe and Russia\",\n",
    " 'algeria' : \"Africa and Middle-East\",\n",
    " 'argentina': \"Central and South America\",\n",
    " 'armenia' : \"Africa and Middle-East\",\n",
    " 'aruba': \"Central and South America\",\n",
    " 'australia': \"North America and Australia\",\n",
    " 'austria': \"Western Europe\",\n",
    " 'azerbaijan' : \"Africa and Middle-East\",\n",
    " 'bahamas': \"Central and South America\",\n",
    " 'bahrain' : \"Africa and Middle-East\",\n",
    " 'bangladesh': \"Asia\",\n",
    " 'belgium': \"Western Europe\",\n",
    " 'bhutan': \"Asia\",\n",
    " 'bolivia': \"Central and South America\",\n",
    " 'bosnia and herzegovina' : \"Eastern Europe and Russia\",\n",
    " 'brazil': \"Central and South America\",\n",
    " 'bulgaria' : \"Eastern Europe and Russia\",\n",
    " 'burkina faso' : \"Africa and Middle-East\",\n",
    " 'burma': \"Asia\",\n",
    " 'cambodia': \"Asia\",\n",
    " 'cameroon' : \"Africa and Middle-East\",\n",
    " 'canada': \"North America and Australia\",\n",
    " 'chile': \"Central and South America\",\n",
    " 'china': \"Asia\",\n",
    " 'colombia': \"Central and South America\",\n",
    " 'congo' : \"Africa and Middle-East\",\n",
    " 'costa rica': \"Central and South America\",\n",
    " 'crime' : \"Eastern Europe and Russia\",\n",
    " 'croatia' : \"Eastern Europe and Russia\",\n",
    " 'cuba': \"Central and South America\",\n",
    " 'cyprus' : \"Eastern Europe and Russia\",\n",
    " 'czech republic' : \"Eastern Europe and Russia\",\n",
    " 'czechoslovakia' : \"Eastern Europe and Russia\",\n",
    " 'democratic republic of the congo' : \"Africa and Middle-East\",\n",
    " 'denmark': \"Western Europe\",\n",
    " 'egypt' : \"Africa and Middle-East\",\n",
    " 'estonia' : \"Eastern Europe and Russia\",\n",
    " 'ethiopia' : \"Africa and Middle-East\",\n",
    " 'finland': \"Western Europe\",\n",
    " 'france': \"Western Europe\",\n",
    " 'georgia' : \"Africa and Middle-East\",\n",
    " 'germany': \"Western Europe\",\n",
    " 'greece' : \"Eastern Europe and Russia\",\n",
    " 'haiti': \"Central and South America\",\n",
    " 'hong kong': \"Asia\",\n",
    " 'hungary' : \"Eastern Europe and Russia\",\n",
    " 'iceland': \"Western Europe\",\n",
    " 'india': \"Asia\",\n",
    " 'indonesia': \"Asia\",\n",
    " 'iran' : \"Africa and Middle-East\",\n",
    " 'iraq' : \"Africa and Middle-East\",\n",
    " 'iraqi kurdistan' : \"Africa and Middle-East\",\n",
    " 'ireland': \"Western Europe\",\n",
    " 'isle of man': \"Western Europe\",\n",
    " 'israel' : \"Africa and Middle-East\",\n",
    " 'italy': \"Western Europe\",\n",
    " 'jamaica': \"Central and South America\",\n",
    " 'japan': \"Asia\",\n",
    " 'jordan' : \"Africa and Middle-East\",\n",
    " 'kenya' : \"Africa and Middle-East\",\n",
    " 'korea': \"Asia\",\n",
    " 'kuwait' : \"Africa and Middle-East\",\n",
    " 'lebanon' : \"Africa and Middle-East\",\n",
    " 'libya' : \"Africa and Middle-East\",\n",
    " 'lithuania' : \"Eastern Europe and Russia\",\n",
    " 'luxembourg': \"Western Europe\",\n",
    " 'macau': \"Asia\",\n",
    " 'malaysia': \"Asia\",\n",
    " 'mali' : \"Africa and Middle-East\",\n",
    " 'malta': \"Western Europe\",\n",
    " 'mexico': \"Central and South America\",\n",
    " 'monaco': \"Western Europe\",\n",
    " 'mongolia': \"Asia\",\n",
    " 'montenegro' : \"Eastern Europe and Russia\",\n",
    " 'morocco' : \"Africa and Middle-East\",\n",
    " 'nepal': \"Asia\",\n",
    " 'netherlands': \"Western Europe\",\n",
    " 'new zealand': \"North America and Australia\",\n",
    " 'nigeria' : \"Africa and Middle-East\",\n",
    " 'norway': \"Western Europe\",\n",
    " 'pakistan' : \"Africa and Middle-East\",\n",
    " 'palestinian territories' : \"Africa and Middle-East\",\n",
    " 'panama': \"Central and South America\",\n",
    " 'peru': \"Central and South America\",\n",
    " 'philippines': \"Asia\",\n",
    " 'poland' : \"Eastern Europe and Russia\",\n",
    " 'portugal': \"Western Europe\",\n",
    " 'puerto rico': \"Central and South America\",\n",
    " 'republic of macedonia' : \"Eastern Europe and Russia\",\n",
    " 'romania' : \"Eastern Europe and Russia\",\n",
    " 'russia' : \"Eastern Europe and Russia\",\n",
    " 'senegal' : \"Africa and Middle-East\",\n",
    " 'serbia' : \"Eastern Europe and Russia\",\n",
    " 'serbia and montenegro' : \"Eastern Europe and Russia\",\n",
    " 'singapore': \"Asia\",\n",
    " 'slovakia' : \"Eastern Europe and Russia\",\n",
    " 'slovenia' : \"Eastern Europe and Russia\",\n",
    " 'south africa' : \"Africa and Middle-East\",\n",
    " 'south korea': \"Asia\",\n",
    " 'spain': \"Western Europe\",\n",
    " 'sri lanka': \"Asia\",\n",
    " 'sweden': \"Western Europe\",\n",
    " 'switzerland': \"Western Europe\",\n",
    " 'taiwan': \"Asia\",\n",
    " 'thailand': \"Asia\",\n",
    " 'tunisia' : \"Africa and Middle-East\",\n",
    " 'turkey' : \"Africa and Middle-East\",\n",
    " 'ukraine' : \"Eastern Europe and Russia\",\n",
    " 'united arab emirates' : \"Africa and Middle-East\",\n",
    " 'united kingdom': \"Western Europe\",\n",
    " 'united states of america': \"North America and Australia\",\n",
    " 'uruguay': \"Central and South America\",\n",
    " 'uzbekistan' : \"Africa and Middle-East\",\n",
    " 'venezuela': \"Central and South America\",\n",
    " 'vietnam': \"Asia\",\n",
    " 'yugoslavia' : \"Eastern Europe and Russia\",\n",
    " 'zambia' : \"Africa and Middle-East\",\n",
    " 'zimbabwe' : \"Africa and Middle-East\"\n",
    "}\n",
    "\n",
    "COUNTRY_ENCODING = { \n",
    "    \"North America and Australia\": [1,0,0,0,0,0],\n",
    "    \"Western Europe\":              [0,1,0,0,0,0],\n",
    "    \"Asia\":                        [0,0,1,0,0,0],\n",
    "    \"Africa and Middle-East\":      [0,0,0,1,0,0],\n",
    "    \"Eastern Europe and Russia\":   [0,0,0,0,1,0],\n",
    "    \"Central and South America\":   [0,0,0,0,0,1]\n",
    "}\n",
    "\n",
    "CONTINENT_LIST = [\"North America and Australia\",\"Western Europe\",\"Asia\",\n",
    "                  \"Africa and Middle-East\",\"Eastern Europe and Russia\", \n",
    "                  \"Central and South America\"]\n",
    "\n",
    "GENRE_MAPPING = {'absurdism': [\"comedy\"],\n",
    " 'acid western': [\"adventure\",\"action\"],\n",
    " 'action': [\"action\"],\n",
    " 'action comedy': [\"action\",\"comedy\"],\n",
    " 'action thrillers': [\"thriller\",\"action\"],\n",
    " 'action/adventure': [\"action\",\"adventure\"],\n",
    " 'addiction drama': [\"drama\"],\n",
    " 'adult': [\"adult\"],\n",
    " 'adventure': [\"adventure\"],\n",
    " 'adventure comedy': [\"adventure\",\"comedy\"],\n",
    " 'airplanes and airports': [\"other\"],\n",
    " 'albino bias': [\"drama\"],\n",
    " 'alien film': [\"action\",\"adventure\"],\n",
    " 'alien invasion': [\"action\"],\n",
    " 'americana': [\"drama\"],\n",
    " 'animal picture': [\"other\"],\n",
    " 'animals': [\"other\"],\n",
    " 'animated cartoon': [\"animation\"],\n",
    " 'animated musical': [\"animation\"],\n",
    " 'animation': [\"animation\"],\n",
    " 'anime': [\"animation\"],\n",
    " 'anthology': [\"genre\"],\n",
    " 'anthropology': [\"other\"],\n",
    " 'anti-war': [\"drama\"],\n",
    " 'anti-war film': [\"drama\"],\n",
    " 'apocalyptic and post-apocalyptic fiction': [\"action\",\"fantasy\"],\n",
    " 'archaeology': [\"other\"],\n",
    " 'archives and records': [\"other\"],\n",
    " 'art film': [\"genre\"],\n",
    " 'auto racing': [\"other\"],\n",
    " 'avant-garde': [\"genre\"],\n",
    " 'b-movie': [\"comedy\"],\n",
    " 'b-western': [\"action\",\"comedy\"],\n",
    " 'backstage musical': [\"other\"],\n",
    " 'baseball': [\"other\"],\n",
    " 'beach film': [\"other\"],\n",
    " 'beach party film': [\"comedy\"],\n",
    " 'bengali cinema': [\"other\"],\n",
    " 'biker film':[\"action\"],\n",
    " 'biographical film': [\"other\"],\n",
    " 'biography': [\"other\"],\n",
    " 'biopic [feature]': [\"other\"],\n",
    " 'black comedy': [\"comedy\"],\n",
    " 'black-and-white': [\"other\"],\n",
    " 'blaxploitation':[\"drama\"],\n",
    " 'bloopers & candid camera': [\"comedy\"],\n",
    " 'bollywood': [\"other\"],\n",
    " 'boxing': [\"other\"],\n",
    " 'breakdance': [\"other\"],\n",
    " 'british empire film': [\"other\"],\n",
    " 'british new wave': [\"genre\"],\n",
    " 'bruceploitation':[\"action\"],\n",
    " 'buddy cop': [\"action\",\"comedy\"],\n",
    " 'buddy film': [\"comedy\"],\n",
    " 'buddy picture': [\"comedy\"],\n",
    " 'business': [\"other\"],\n",
    " 'camp': [\"other\"],\n",
    " 'caper story': [\"thriller\"],\n",
    " 'cavalry film': [\"action\"],\n",
    " 'chase movie': [\"thriller\"],\n",
    " 'childhood drama': [\"drama\"],\n",
    " \"children's\": [\"family\"],\n",
    " \"children's entertainment\": [\"family\"],\n",
    " \"children's fantasy\": [\"family\",\"fantasy\"],\n",
    " \"children's issues\": [\"drama\"],\n",
    " \"children's/family\": [\"family\"],\n",
    " 'chinese movies': [\"other\"],\n",
    " 'christian film': [\"other\"],\n",
    " 'christmas movie': [\"other\"],\n",
    " 'clay animation': [\"animation\"],\n",
    " 'cold war': [\"adventure\",\"action\"],\n",
    " 'combat films': [\"action\"],\n",
    " 'comdedy': [\"comedy\"],\n",
    " 'comedy': [\"comedy\"],\n",
    " 'comedy film': [\"comedy\"],\n",
    " 'comedy horror': [\"horror\",\"comedy\"],\n",
    " 'comedy of errors': [\"comedy\"],\n",
    " 'comedy of manners': [\"comedy\"],\n",
    " 'comedy thriller': [\"thriller\",\"comedy\"],\n",
    " 'comedy western': [\"action\",\"comedy\"],\n",
    " 'comedy-drama': [\"drama\",\"comedy\"],\n",
    " 'coming of age': [\"comedy\"],\n",
    " 'coming-of-age film': [\"comedy\"],\n",
    " 'computer animation': [\"animation\"],\n",
    " 'computers': [\"animation\"],\n",
    " 'concert film': [\"other\"],\n",
    " 'conspiracy fiction': [\"thriller\"],\n",
    " 'costume adventure': [\"adventure\"],\n",
    " 'costume drama': [\"drama\"],\n",
    " 'costume horror': [\"horror\"],\n",
    " 'courtroom comedy': [\"comedy\"],\n",
    " 'courtroom drama': [\"drama\"],\n",
    " 'creature film': [\"adventure\",\"fantasy\"],\n",
    " 'crime': [\"thriller\"],\n",
    " 'crime comedy': [\"thriller\",\"comedy\"],\n",
    " 'crime drama': [\"thriller\",\"drama\"],\n",
    " 'crime fiction': [\"thriller\"],\n",
    " 'crime thriller': [\"thriller\"],\n",
    " 'cult': [\"other\"],\n",
    " 'culture & society': [\"other\"],\n",
    " 'cyberpunk': [\"fantasy\"],\n",
    " 'czechoslovak new wave': [\"genre\"],\n",
    " 'dance': [\"other\"],\n",
    " 'demonic child': [\"horror\"],\n",
    " 'detective': [\"thriller\"],\n",
    " 'detective fiction': [\"thriller\"],\n",
    " 'disaster': [\"drama\"],\n",
    " 'docudrama': [\"drama\"],\n",
    " 'documentary': [\"other\"],\n",
    " 'dogme 95': [\"genre\"],\n",
    " 'domestic comedy': [\"comedy\"],\n",
    " 'doomsday film': [\"fantasy\"],\n",
    " 'drama': [\"drama\"],\n",
    " 'dystopia': [\"drama\",\"fantasy\"],\n",
    " 'ealing comedies': [\"comedy\"],\n",
    " 'early black cinema': [\"other\"],\n",
    " 'education': [\"family\"],\n",
    " 'educational': [\"family\"],\n",
    " 'ensemble film': [\"genre\"],\n",
    " 'environmental science': [\"other\"],\n",
    " 'epic': [\"adventure\"],\n",
    " 'epic western': [\"adventure\",\"action\"],\n",
    " 'erotic drama': [\"adult\",\"drama\"],\n",
    " 'erotic thriller': [\"thriller\",\"adult\"],\n",
    " 'erotica': [\"adult\"],\n",
    " 'escape film': [\"thriller\"],\n",
    " 'essay film': [\"genre\"],\n",
    " 'existentialism': [\"genre\"],\n",
    " 'experimental film': [\"genre\"],\n",
    " 'exploitation': [\"drama\"],\n",
    " 'expressionism': [\"genre\"],\n",
    " 'extreme sports': [\"other\"],\n",
    " 'fairy tale': [\"fantasy\",\"adventure\"],\n",
    " 'family & personal relationships': [\"drama\"],\n",
    " 'family drama': [\"drama\"],\n",
    " 'family film': [\"family\"],\n",
    " 'family-oriented adventure': [\"family\",\"adventure\"],\n",
    " 'fan film': [\"other\"],\n",
    " 'fantasy': [\"fantasy\"],\n",
    " 'fantasy adventure': [\"fantasy\",\"adventure\"],\n",
    " 'fantasy comedy': [\"fantasy\",\"comedy\"],\n",
    " 'fantasy drama': [\"fantasy\",\"drama\"],\n",
    " 'feature film': [\"other\"],\n",
    " 'female buddy film': [\"comedy\"],\n",
    " 'feminist film': [\"drama\"],\n",
    " 'fictional film': [\"other\"],\n",
    " 'filipino': [\"other\"],\n",
    " 'filipino movies': [\"other\"],\n",
    " 'film': [\"other\"],\n",
    " 'film & television history': [\"other\"],\n",
    " 'film adaptation': [\"other\"],\n",
    " 'film noir': [\"thriller\"],\n",
    " 'film Ã  clef': [\"drama\"],\n",
    " 'film-opera': [\"other\"],\n",
    " 'filmed play': [\"other\"],\n",
    " 'finance & investing': [\"other\"],\n",
    " 'foreign legion':[\"action\"],\n",
    " 'future noir': [\"fantasy\",\"drama\"],\n",
    " 'gangster film': [\"thriller\",\"action\"],\n",
    " 'gay': [\"drama\"],\n",
    " 'gay interest': [\"drama\"],\n",
    " 'gay pornography': [\"adult\"],\n",
    " 'gay themed': [\"drama\"],\n",
    " 'gender issues': [\"drama\"],\n",
    " 'giallo': [\"thriller\"],\n",
    " 'glamorized spy film': [\"thriller\"],\n",
    " 'goat gland': [\"genre\"],\n",
    " 'gothic film': [\"genre\"],\n",
    " 'graphic & applied arts': [\"genre\"],\n",
    " 'gross out': [\"comedy\"],\n",
    " 'gross-out film': [\"comedy\"],\n",
    " 'gulf war':[\"action\"],\n",
    " 'hagiography': [\"other\"],\n",
    " 'hardcore pornography': [\"adult\"],\n",
    " 'haunted house film': [\"horror\"],\n",
    " 'health & fitness': [\"other\"],\n",
    " 'heaven-can-wait fantasies': [\"fantasy\"],\n",
    " 'heavenly comedy': [\"comedy\"],\n",
    " 'heist': [\"action\"],\n",
    " 'hip hop movies': [\"other\"],\n",
    " 'historical documentaries': [\"other\"],\n",
    " 'historical drama': [\"drama\"],\n",
    " 'historical epic': [\"adventure\"],\n",
    " 'historical fiction': [\"other\"],\n",
    " 'history': [\"other\"],\n",
    " 'holiday film': [\"comedy\"],\n",
    " 'horror': [\"horror\"],\n",
    " 'horror comedy': [\"horror\",\"comedy\"],\n",
    " 'horse racing': [\"other\"],\n",
    " 'humour': [\"comedy\"],\n",
    " 'hybrid western': [\"adventure\",\"action\"],\n",
    " 'illnesses & disabilities': [\"drama\"],\n",
    " 'indian western': [\"adventure\",\"action\"],\n",
    " 'indie': [\"genre\"],\n",
    " 'inspirational drama': [\"drama\"],\n",
    " 'instrumental music': [\"other\"],\n",
    " 'interpersonal relationships': [\"drama\"],\n",
    " 'inventions & innovations': [\"other\"],\n",
    " 'japanese movies': [\"other\"],\n",
    " 'journalism': [\"other\"],\n",
    " 'jukebox musical': [\"other\"],\n",
    " 'jungle film': [\"adventure\"],\n",
    " 'juvenile delinquency film': [\"drama\"],\n",
    " 'kafkaesque': [\"genre\"],\n",
    " 'kitchen sink realism': [\"genre\"],\n",
    " 'language & literature': [\"genre\"],\n",
    " 'latino': [\"other\"],\n",
    " 'law & crime': [\"thriller\"],\n",
    " 'legal drama': [\"drama\"],\n",
    " 'lgbt': [\"drama\"],\n",
    " 'libraries and librarians': [\"other\"],\n",
    " 'live action': [\"other\"],\n",
    " 'malayalam cinema': [\"other\"],\n",
    " 'marriage drama': [\"drama\"],\n",
    " 'martial arts film': [\"action\"],\n",
    " 'master criminal films': [\"thriller\"],\n",
    " 'media satire': [\"other\"],\n",
    " 'media studies': [\"other\"],\n",
    " 'medical fiction': [\"other\"],\n",
    " 'melodrama': [\"drama\"],\n",
    " 'mockumentary': [\"other\"],\n",
    " 'mondo film': [\"genre\"],\n",
    " 'monster': [\"horror\",\"action\"],\n",
    " 'monster movie': [\"horror\",\"action\"],\n",
    " 'movie serial': [\"other\"],\n",
    " 'movies about gladiators': [\"other\"],\n",
    " 'mumblecore': [\"genre\"],\n",
    " 'music': [\"other\"],\n",
    " 'musical': [\"other\"],\n",
    " 'musical comedy': [\"comedy\"],\n",
    " 'musical drama': [\"drama\"],\n",
    " 'mystery': [\"thriller\"],\n",
    " 'mythological fantasy': [\"fantasy\"],\n",
    " 'natural disaster': [\"other\"],\n",
    " 'natural horror films': [\"horror\"],\n",
    " 'nature': [\"other\"],\n",
    " 'neo-noir': [\"thriller\"],\n",
    " 'neorealism': [\"genre\"],\n",
    " 'new hollywood': [\"genre\"],\n",
    " 'new queer cinema': [\"drama\"],\n",
    " 'news': [\"other\"],\n",
    " 'ninja movie': [\"action\"],\n",
    " 'northern': [\"genre\"],\n",
    " 'operetta': [\"other\"],\n",
    " 'outlaw': [\"other\"],\n",
    " 'outlaw biker film': [\"other\"],\n",
    " 'parkour in popular culture': [\"action\"],\n",
    " 'parody': [\"comedy\"],\n",
    " 'patriotic film': [\"other\"],\n",
    " 'period horror': [\"horror\"],\n",
    " 'period piece': [\"drama\"],\n",
    " 'pinku eiga': [\"adult\"],\n",
    " 'plague': [\"drama\"],\n",
    " 'point of view shot': [\"other\"],\n",
    " 'political cinema': [\"other\"],\n",
    " 'political documetary': [\"other\"],\n",
    " 'political drama': [\"drama\"],\n",
    " 'political satire': [\"drama\"],\n",
    " 'political thriller': [\"thriller\"],\n",
    " 'pornographic movie': [\"adult\"],\n",
    " 'pornography': [\"adult\"],\n",
    " 'pre-code': [\"other\"],\n",
    " 'prison': [\"action\"],\n",
    " 'prison escape': [\"action\"],\n",
    " 'prison film': [\"action\"],\n",
    " 'private military company': [\"action\"],\n",
    " 'propaganda film': [\"other\"],\n",
    " 'psycho-biddy': [\"horror\",\"thriller\"],\n",
    " 'psychological horror': [\"horror\"],\n",
    " 'psychological thriller': [\"thriller\"],\n",
    " 'punk rock': [\"genre\"],\n",
    " 'race movie': [\"action\"],\n",
    " 'reboot': [\"other\"],\n",
    " 'religious film': [\"other\"],\n",
    " 'remake': [\"other\"],\n",
    " 'revenge': [\"action\"],\n",
    " 'revisionist fairy tale': [\"adventure\",\"fantasy\"],\n",
    " 'revisionist western': [\"adventure\",\"action\"],\n",
    " 'road movie': [\"other\"],\n",
    " 'road-horror': [\"horror\"],\n",
    " 'roadshow theatrical release': [\"other\"],\n",
    " 'roadshow/carny': [\"other\"],\n",
    " 'rockumentary': [\"other\"],\n",
    " 'romance film': [\"other\"],\n",
    " 'romantic comedy': [\"comedy\"],\n",
    " 'romantic drama': [\"drama\"],\n",
    " 'romantic fantasy': [\"fantasy\"],\n",
    " 'romantic thriller': [\"thriller\"],\n",
    " 'samurai cinema': [\"adventure\",\"action\"],\n",
    " 'satire': [\"comedy\"],\n",
    " 'school story': [\"family\"],\n",
    " 'sci-fi adventure': [\"fantasy\",\"adventure\"],\n",
    " 'sci-fi horror': [\"fantasy\",\"horror\"],\n",
    " 'sci-fi thriller': [\"fantasy\",\"thriller\"],\n",
    " 'science fiction': [\"fantasy\"],\n",
    " 'science fiction western': [\"adventure\",\"fantasy\",\"action\"],\n",
    " 'screwball comedy': [\"comedy\"],\n",
    " 'sex comedy': [\"comedy\"],\n",
    " 'sexploitation': [\"drama\"],\n",
    " 'short film': [\"other\"],\n",
    " 'silent film': [\"other\"],\n",
    " 'singing cowboy': [\"action\",\"adventure\"],\n",
    " 'slapstick': [\"comedy\"],\n",
    " 'slasher': [\"horror\",\"action\"],\n",
    " 'slice of life story': [\"drama\"],\n",
    " 'social issues': [\"drama\"],\n",
    " 'social problem film': [\"drama\"],\n",
    " 'softcore porn': [\"adult\"],\n",
    " 'space opera': [\"fantasy\",\"adventure\"],\n",
    " 'space western': [\"adventure\",\"action\"],\n",
    " 'spaghetti western': [\"adventure\",\"action\"],\n",
    " 'splatter film': [\"horror\"],\n",
    " 'sports': [\"other\"],\n",
    " 'spy': [\"thriller\"],\n",
    " 'stand-up comedy': [\"comedy\"],\n",
    " 'star vehicle': [\"other\"],\n",
    " 'steampunk': [\"fantasy\"],\n",
    " 'stoner film': [\"genre\"],\n",
    " 'stop motion': [\"animation\"],\n",
    " 'superhero': [\"action\"],\n",
    " 'superhero movie': [\"action\"],\n",
    " 'supermarionation': [\"animation\"],\n",
    " 'supernatural': [\"fantasy\"],\n",
    " 'surrealism': [\"genre\"],\n",
    " 'suspense': [\"thriller\"],\n",
    " 'swashbuckler films': [\"action\",\"adventure\"],\n",
    " 'sword and sandal': [\"adventure\"],\n",
    " 'sword and sorcery': [\"fantasy\",\"adventure\"],\n",
    " 'sword and sorcery films': [\"fantasy\",\"adventure\"],\n",
    " 'tamil cinema': [\"other\"],\n",
    " 'teen': [\"family\"],\n",
    " 'television movie': [\"other\"],\n",
    " 'the netherlands in world war ii': [\"action\"],\n",
    " 'therimin music': [\"other\"],\n",
    " 'thriller': [\"thriller\"],\n",
    " 'time travel': [\"adventure\"],\n",
    " 'tokusatsu': [\"other\"],\n",
    " 'tollywood': [\"other\"],\n",
    " 'tragedy': [\"drama\"],\n",
    " 'tragicomedy': [\"comedy\"],\n",
    " 'travel': [\"adventure\"],\n",
    " 'vampire movies': [\"horror\",\"action\"],\n",
    " 'war effort': [\"action\"],\n",
    " 'war film': [\"action\"],\n",
    " 'werewolf fiction': [\"horror\"],\n",
    " 'western': [\"adventure\",\"action\"],\n",
    " 'whodunit': [\"thriller\"],\n",
    " 'women in prison films': [\"drama\"],\n",
    " 'workplace comedy': [\"comedy\"],\n",
    " 'world cinema': [\"other\"],\n",
    " 'world history': [\"other\"],\n",
    " 'wuxia': [\"adventure\"],\n",
    " 'z movie': [\"horror\"],\n",
    " 'zombie film': [\"horror\"]}\n",
    "\n",
    "GENRE_ENCODING = {\n",
    "    \"action\":    [1,0,0,0,0,0,0,0,0,0,0],\n",
    "    \"adventure\": [0,1,0,0,0,0,0,0,0,0,0],\n",
    "    \"comedy\":    [0,0,1,0,0,0,0,0,0,0,0],\n",
    "    \"drama\":     [0,0,0,1,0,0,0,0,0,0,0],\n",
    "    \"thriller\":  [0,0,0,0,1,0,0,0,0,0,0],\n",
    "    \"horror\":    [0,0,0,0,0,1,0,0,0,0,0],\n",
    "    \"animation\": [0,0,0,0,0,0,1,0,0,0,0],\n",
    "    \"family\":    [0,0,0,0,0,0,0,1,0,0,0],\n",
    "    \"adult\":     [0,0,0,0,0,0,0,0,1,0,0],\n",
    "    \"fantasy\":   [0,0,0,0,0,0,0,0,0,1,0],\n",
    "    \"genre\":     [0,0,0,0,0,0,0,0,0,0,1],\n",
    "    \"other\":     [0,0,0,0,0,0,0,0,0,0,0]\n",
    "}\n",
    "\n",
    "GENRE_LIST = [\"action\",\"adventure\",\"comedy\",\"drama\",\"thriller\",\"horror\",\n",
    "                   \"animation\",\"children\",\"adult\",\"fantasy\",\"genre\"]\n",
    "\n",
    "# These parameters control the formation of the dataframe for regression\n",
    "# drop: Columns to drop before applying any transform to the data\n",
    "# nan_filtering: Columns on which we want to remove rows with nans.\n",
    "#                If 'all', then apply on every one.\n",
    "# decades: List of decades on which to apply the regression. \n",
    "#          If empty list then all decades will be taken.\n",
    "# log: Columns on which to apply a log transform.\n",
    "# standardize: Columns to standardize.\n",
    "# post_drop: Columns to drop before doing the regression.\n",
    "DEFAULT_PARAMETERS = {\n",
    "            \"drop\": [\"name\",\"revenue\",\"has_common_character_name\",\"has_common_language\",\"language_number\",\"character_number\"],\n",
    "            \"nan_filtering\":[\"all\"],\n",
    "            \"decades\":[],\n",
    "            \"log\":[],\n",
    "            \"standardize\":[\"title_length\"],\n",
    "            \"post_drop\": [\"release_date\",\"num_votes\",\n",
    "                            \"runtime\",\"decade\",\"average_rating\",\n",
    "                            \"combinned_best_rating\"]}\n",
    "\n",
    "SUCCESS_THRESHOLD = 7.5\n",
    "\n",
    "NE_FULL_LIST = [\"ORGANIZATION\",\"PERSON\",\"LOCATION\",\n",
    "                \"DATE\",\"TIME\",\"MONEY\",\n",
    "                \"PERCENT\",\"FACILITY\",\"GPE\"]\n",
    "\n",
    "EPSILON = 1e-4 # Set to 1e-4 empirically, but idea is to have at least one occurence in all corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2aae8",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33e62d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_pickle(\"../../data/post_processing//country_df.pkl\")\n",
    "comes_from_df = pd.read_pickle(\"../../data/post_processing/comes_from_df.pkl\")\n",
    "genre_df = pd.read_pickle(\"../../data/post_processing/genre_df.pkl\")\n",
    "is_of_type_df = pd.read_pickle(\"../../data/post_processing/is_of_type_df.pkl\")\n",
    "language_df = pd.read_pickle(\"../../data/post_processing/language_df.pkl\")\n",
    "spoken_languages_df = pd.read_pickle(\"../../data/post_processing/spoken_languages_df.pkl\")\n",
    "character_df = pd.read_pickle(\"../../data/post_processing/character_df.pkl\")\n",
    "actor_df = pd.read_pickle(\"../../data/post_processing/actor_df.pkl\")\n",
    "movie_df = pd.read_pickle(\"../../data/post_processing/movie_df.pkl\")\n",
    "belongs_to_df = pd.read_pickle(\"../../data/post_processing/belongs_to_df.pkl\")\n",
    "play_df = pd.read_pickle(\"../../data/post_processing/play_df.pkl\")\n",
    "appears_in_df = pd.read_pickle(\"../../data/post_processing/appears_in_df.pkl\")\n",
    "wikipedia_imdb_mapping_table = pd.read_pickle(\"../../data/generated/wikipedia_imdb_mapping_df.pkl\")\n",
    "is_directed_by_df = pd.read_pickle(\"../../data/post_processing/is_directed_by_df.pkl\")\n",
    "director_df = pd.read_pickle(\"../../data/post_processing/director_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5f828",
   "metadata": {},
   "source": [
    "## Create Regression DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7799a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df = movie_df.copy()\n",
    "movie_regression_df.drop([\"freebase_id\",\"plot\"],axis=1,inplace=True)\n",
    "movie_regression_df[\"num_votes\"] = movie_regression_df[\"num_votes\"].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4850587",
   "metadata": {},
   "source": [
    "## Countries\n",
    "\n",
    "For the countries we can already try to group per continent. It will give an idea of the different local influence without going in too much details. We suggest the following partition based on our previous analyses:\n",
    "\n",
    "- North America and Australia\n",
    "- Central and South America\n",
    "- Western Europe\n",
    "- Eastern Europe and Russia\n",
    "- Africa and Middle-East\n",
    "- Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410da0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_movie_df = comes_from_df.copy()\n",
    "country_movie_df[\"country_encoding\"] = country_movie_df[\"country_name\"].apply(\n",
    "    lambda c: COUNTRY_CONTINENT_MAPPING[c])\n",
    "country_movie_df[\"country_encoding\"] = country_movie_df[\"country_encoding\"].apply(\n",
    "    lambda c: np.array(COUNTRY_ENCODING[c]))\n",
    "for continent in CONTINENT_LIST:\n",
    "    country_movie_df[continent] = country_movie_df[\"country_encoding\"].apply(\n",
    "        lambda l: l[CONTINENT_LIST.index(continent)])\n",
    "    movie_regression_df[continent] = country_movie_df.groupby(\"movie_id\")[continent].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1b3cb",
   "metadata": {},
   "source": [
    "## Actors\n",
    "\n",
    "For the actors, we thought about the following features:\n",
    "- #number of actors in the top 5% (or 1% ?)\n",
    "- #number of actors\n",
    "- mean actor age\n",
    "- gender balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07189e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1014 actors in the top 99%.\n"
     ]
    }
   ],
   "source": [
    "percentile = 99\n",
    "actor_movie_count = appears_in_df.groupby(\"actor_id\")[\"movie_id\"].count().values\n",
    "threshold = np.percentile(actor_movie_count,percentile)\n",
    "is_actor_above_threshold = appears_in_df.groupby(\"actor_id\")[\"movie_id\"].count().sort_index() >= threshold\n",
    "top_k_actors = actor_df[is_actor_above_threshold.values]\n",
    "print(f\"There are {len(top_k_actors)} actors in the top {percentile}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650f0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_movie_df = appears_in_df.merge(actor_df[\"gender\"],how=\"left\",on=\"actor_id\")\n",
    "actor_movie_df[\"gender\"] = actor_movie_df[\"gender\"].apply(\n",
    "    lambda g: -1 if g == \"M\" else 1 if g == \"F\" else g)\n",
    "actor_movie_df[\"is_top_k\"] = actor_movie_df[\"actor_id\"].isin(set(top_k_actors.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663baac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"actor_number\"] = actor_movie_df.groupby(\"movie_id\")[\"actor_id\"].count()\n",
    "movie_regression_df[\"mean_actor_age\"] = actor_movie_df.groupby(\"movie_id\")[\"actor_age\"].mean()\n",
    "movie_regression_df[\"gender_ratio\"] = actor_movie_df.groupby(\"movie_id\")[\"gender\"].mean()\n",
    "movie_regression_df[\"has_famous_actor\"] = actor_movie_df.groupby(\"movie_id\")[\"is_top_k\"].max()\n",
    "movie_regression_df[\"has_famous_actor\"] = movie_regression_df[\"has_famous_actor\"].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d448350",
   "metadata": {},
   "source": [
    "## Genre\n",
    "\n",
    "For the genre we suggest the following features:\n",
    "- #genres\n",
    "- One-hot-encoding of genre cluster:\n",
    "    - action\n",
    "    - adventure\n",
    "    - comedy\n",
    "    - drame\n",
    "    - thriller\n",
    "    - horror\n",
    "    - animation\n",
    "    - children\n",
    "    - adult\n",
    "    - fantasy\n",
    "    - genre\n",
    "    - other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9cd528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_movie_df = is_of_type_df.copy()\n",
    "genre_movie_df[\"genre_encoding\"] = genre_movie_df[\"genre_name\"].apply(lambda g: GENRE_MAPPING[g])\n",
    "genre_movie_df[\"genre_encoding\"] = genre_movie_df[\"genre_encoding\"].apply(\n",
    "    lambda l: np.sum([np.array(GENRE_ENCODING[g]) for g in l],axis=0))\n",
    "for genre in GENRE_LIST:\n",
    "    genre_movie_df[genre] = genre_movie_df[\"genre_encoding\"].apply(\n",
    "        lambda l: l[GENRE_LIST.index(genre)])\n",
    "    movie_regression_df[genre] = genre_movie_df.groupby(\"movie_id\")[genre].max()\n",
    "movie_regression_df[\"genre_number\"] = genre_movie_df.groupby(\"movie_id\")[\"genre_name\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc1dd0",
   "metadata": {},
   "source": [
    "## Languages\n",
    "\n",
    "For the languages we suggest the following features:\n",
    "- #languages\n",
    "- top languages\n",
    "- total population covered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a7b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_language = 5\n",
    "language_movie_df = spoken_languages_df.copy()\n",
    "top_k_languages = set(language_movie_df.groupby(\"language_name\")[\"movie_id\"].count().sort_values(\n",
    "    ascending=False).head(k_language).index)\n",
    "language_movie_df[\"top_language\"] = language_movie_df[\"language_name\"].isin(top_k_languages)\n",
    "movie_regression_df[\"has_common_language\"] = language_movie_df.groupby(\"movie_id\")[\"top_language\"].max()\n",
    "movie_regression_df[\"has_common_language\"] = movie_regression_df[\"has_common_language\"].replace({True: 1, False: 0})\n",
    "movie_regression_df[\"language_number\"] = language_movie_df.groupby(\"movie_id\")[\"language_name\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0310531",
   "metadata": {},
   "source": [
    "## Characters\n",
    "- #characters\n",
    "- usage of common names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0dc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_characters = 20\n",
    "top_k_characters_names = set(character_df[\"character_name\"].value_counts().head(k_characters).index)\n",
    "top_k_characters_ids = set(character_df[character_df[\"character_name\"].isin(top_k_characters_names)].index)\n",
    "character_movie_df = belongs_to_df.copy()\n",
    "character_movie_df[\"common_character_name\"] = character_movie_df[\"character_id\"].isin(top_k_characters_ids)\n",
    "movie_regression_df[\"has_common_character_name\"] = character_movie_df.groupby(\n",
    "    \"movie_id\")[\"common_character_name\"].max()\n",
    "movie_regression_df[\"character_number\"] = character_movie_df.groupby(\n",
    "    \"movie_id\")[\"character_id\"].count()\n",
    "movie_regression_df[\"has_common_character_name\"] = movie_regression_df[\n",
    "    \"has_common_character_name\"].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e39ef",
   "metadata": {},
   "source": [
    "## Decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6505fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"decade\"] = movie_regression_df[\"release_date\"].apply(lambda d: d.year - d.year%10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996ed90",
   "metadata": {},
   "source": [
    "## Movie Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0936792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"title_length\"] = movie_regression_df[\"name\"].apply(lambda n: len(n.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5733b",
   "metadata": {},
   "source": [
    "## Director\n",
    "\n",
    "- Has the director produced a successful movie in the past decades\n",
    "- Has the director produced a successful movie in the past (coarser feature)\n",
    "- Number of movies produced by directors in the past\n",
    "\n",
    "- Number of directors on the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cdb74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def director_metrics_up_to_date(movie_dataframe: pd.DataFrame, director_movies: set, date) -> tuple:\n",
    "    \"\"\"\n",
    "    Compute the number of movies and the best ratings up to the date from the set of movies provided.\n",
    "    \n",
    "    This function allows us to have the history of performance of the set of directors that worked \n",
    "    on a given movie. You give the set of movies of the directors and the date of production of the\n",
    "    current movie and it will return the performance up to the given date.\n",
    "    \n",
    "    :param movie_dataframe: Pandas DataFrame with movie information\n",
    "    :param director_movies: Set of movies directed by the directors of the current movie.\n",
    "    :param date: Date of release of the current movie, thus the metrics are up to this date.\n",
    "    \n",
    "    :return: The number of movies and the best rating up to the given date.\n",
    "    \"\"\"\n",
    "    director_movie_df = movie_dataframe[movie_dataframe.index.isin(director_movies)]\n",
    "    movie_date_df = director_movie_df[director_movie_df[\"release_date\"] < date]\n",
    "    movie_count = len(movie_date_df)\n",
    "    if movie_count == 0:\n",
    "        return 0, None\n",
    "    best_rating = movie_date_df[\"average_rating\"].max()\n",
    "    return movie_count, best_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c641011",
   "metadata": {},
   "outputs": [],
   "source": [
    "director_movies_mapping = is_directed_by_df.groupby(\"director_id\")[\"movie_id\"].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40715261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the set of movies directed by the directors for each movie\n",
    "director_movies_df = is_directed_by_df.copy()\n",
    "director_movies_df[\"director_movies\"] = director_movies_df[\"director_id\"].apply(\n",
    "    lambda d: director_movies_mapping[d])\n",
    "director_movies_df = director_movies_df.groupby(\"movie_id\")[\"director_movies\"].apply(list)\n",
    "director_movies_df = director_movies_df.apply(\n",
    "    lambda movie_list: set([m for movie_set in movie_list for m in list(movie_set)]))\n",
    "director_movies_df = pd.DataFrame(director_movies_df)\n",
    "# Merge DataFrames to recover temporal data and rating\n",
    "new_is_directed_by_df = director_movies_df.merge(\n",
    "    movie_regression_df[[\"average_rating\",\"release_date\"]],how=\"left\",on=\"movie_id\")\n",
    "new_is_directed_by_df[\"combined_features\"] = list(zip(new_is_directed_by_df[\"director_movies\"],new_is_directed_by_df[\"release_date\"]))\n",
    "# Compute performance of the movie directing team up to the release date of each movie.\n",
    "new_is_directed_by_df[\"director_metrics\"] = new_is_directed_by_df[\"combined_features\"].apply(\n",
    "    lambda t: director_metrics_up_to_date(new_is_directed_by_df,t[0],t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc1e16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"combinned_movie_num\"] = new_is_directed_by_df[\"director_metrics\"].apply(lambda t: t[0])\n",
    "movie_regression_df[\"combinned_best_rating\"] = new_is_directed_by_df[\"director_metrics\"].apply(lambda t: t[1])\n",
    "movie_regression_df[\"num_directors\"] = is_directed_by_df.groupby(\"movie_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96fbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"combinned_movie_success\"] = movie_regression_df[\"combinned_best_rating\"] > SUCCESS_THRESHOLD\n",
    "movie_regression_df[\"combinned_movie_success\"] = movie_regression_df[\n",
    "    \"combinned_movie_success\"].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18af69",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "The plot of the movie is certainly a key element in its final quality. Thus we will try to comes with summary features.\n",
    "\n",
    "We will base our analysis on the BOW matrix, which is constructed in the following way:\n",
    "- Preprocess plots: tokenization + casefolding + stopwords and Named Entity removal + lemmatization\n",
    "- BOW creation\n",
    "- BOW matrix creation\n",
    "\n",
    "Then we will extract the following features:\n",
    "- Odds ratio computation in order to capture terms that are more frequent in popular (high ratio) or unpopular (low ratio) movies.\n",
    "- LDA topic extraction, to add a second layer of potential topic but more coarsed and dataset tailored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccef0ef",
   "metadata": {},
   "source": [
    "### Load Locally\n",
    "\n",
    "The processing of the dataset takes some time. Thus you can load directly the following files that will save you the cost of the preprocessing.\n",
    "\n",
    "Once done you can directly jump to the Odds Ratio section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061320b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "movies_with_plot_df = pd.read_pickle(\"../../data/post_processing/plot_df.pkl\")\n",
    "BOW_matrix = load_npz(\"../../data/post_processing/BOW_matrix.npz\")\n",
    "with open(\"../../data/post_processing/BOW_mapping.pkl\", 'rb') as handle:\n",
    "    BOW_dict = pickle.load(handle)\n",
    "reversed_BOW_dict = {v:k for k,v in BOW_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa29240",
   "metadata": {},
   "source": [
    "### Full Pipeline\n",
    "#### Plot Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8505885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jerem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"stopwords\")\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b5510b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, an, upper, class, housewife, becomes, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171005</th>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       plot  \\\n",
       "movie_id                                                      \n",
       "975900    Set in the second half of the 22nd century, th...   \n",
       "261236    Eva, an upper class housewife, becomes frustra...   \n",
       "171005    {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...   \n",
       "\n",
       "                                                  tokenized  \n",
       "movie_id                                                     \n",
       "975900    [Set, in, the, second, half, of, the, 22nd, ce...  \n",
       "261236    [Eva, an, upper, class, housewife, becomes, fr...  \n",
       "171005    [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "movies_with_plot_df = pd.DataFrame(movie_df[~movie_df[\"plot\"].isna()][\"plot\"])\n",
    "movies_with_plot_df[\"tokenized\"] = movies_with_plot_df[\"plot\"].apply(tokenizer.tokenize)\n",
    "movies_with_plot_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d79a4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS + NER\n",
    "def extract_ne(token_list: list, entity_list=[\"PERSON\"]) -> set:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    entity_set = set(entity_list)\n",
    "    tags = nltk.pos_tag(token_list)\n",
    "    tree = nltk.ne_chunk(tags, binary=False)\n",
    "    return set(\n",
    "        \" \".join(i[0] for i in t)\n",
    "        for t in tree\n",
    "        if hasattr(t, \"label\") and t.label() in entity_set\n",
    "     )\n",
    "movies_with_plot_df[\"NER\"] = movies_with_plot_df[\"tokenized\"].apply(extract_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5867540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the NER to the stop words because they carry too noisy information \n",
    "for row_id, row_data in movies_with_plot_df[\"NER\"].apply(lambda l: set(l)).iteritems():\n",
    "    stop_words = stop_words.union(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f109f154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>NER</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>{Mars, Desolation Williams Arriving, Sergeant ...</td>\n",
       "      <td>[second, half, 22nd, century, film, depicts, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, an, upper, class, housewife, becomes, fr...</td>\n",
       "      <td>{Johns, Eva, Yvonne Eva, Chris}</td>\n",
       "      <td>[upper, class, housewife, becomes, frustrated,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171005</th>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...</td>\n",
       "      <td>{Catherine, Henry V, Plot, Henry, Henry VI}</td>\n",
       "      <td>[dateact, 1act, 2act, 3act, 4act, 5, negotiati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       plot  \\\n",
       "movie_id                                                      \n",
       "975900    Set in the second half of the 22nd century, th...   \n",
       "261236    Eva, an upper class housewife, becomes frustra...   \n",
       "171005    {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...   \n",
       "\n",
       "                                                  tokenized  \\\n",
       "movie_id                                                      \n",
       "975900    [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "261236    [Eva, an, upper, class, housewife, becomes, fr...   \n",
       "171005    [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...   \n",
       "\n",
       "                                                        NER  \\\n",
       "movie_id                                                      \n",
       "975900    {Mars, Desolation Williams Arriving, Sergeant ...   \n",
       "261236                      {Johns, Eva, Yvonne Eva, Chris}   \n",
       "171005          {Catherine, Henry V, Plot, Henry, Henry VI}   \n",
       "\n",
       "                                               no_stopwords  \n",
       "movie_id                                                     \n",
       "975900    [second, half, 22nd, century, film, depicts, p...  \n",
       "261236    [upper, class, housewife, becomes, frustrated,...  \n",
       "171005    [dateact, 1act, 2act, 3act, 4act, 5, negotiati...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords and Casefolding\n",
    "movies_with_plot_df[\"no_stopwords\"] = movies_with_plot_df[\"tokenized\"].apply(\n",
    "    lambda l: [s.casefold() for s in l if s.casefold() not in stop_words and s not in stop_words])\n",
    "movies_with_plot_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06c62a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>NER</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>{Mars, Desolation Williams Arriving, Sergeant ...</td>\n",
       "      <td>[second, half, 22nd, century, film, depicts, p...</td>\n",
       "      <td>[second, half, 22nd, century, film, depicts, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, an, upper, class, housewife, becomes, fr...</td>\n",
       "      <td>{Johns, Eva, Yvonne Eva, Chris}</td>\n",
       "      <td>[upper, class, housewife, becomes, frustrated,...</td>\n",
       "      <td>[upper, class, housewife, becomes, frustrated,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171005</th>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...</td>\n",
       "      <td>{Catherine, Henry V, Plot, Henry, Henry VI}</td>\n",
       "      <td>[dateact, 1act, 2act, 3act, 4act, 5, negotiati...</td>\n",
       "      <td>[dateact, 1act, 2act, 3act, 4act, 5, negotiati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       plot  \\\n",
       "movie_id                                                      \n",
       "975900    Set in the second half of the 22nd century, th...   \n",
       "261236    Eva, an upper class housewife, becomes frustra...   \n",
       "171005    {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...   \n",
       "\n",
       "                                                  tokenized  \\\n",
       "movie_id                                                      \n",
       "975900    [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "261236    [Eva, an, upper, class, housewife, becomes, fr...   \n",
       "171005    [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...   \n",
       "\n",
       "                                                        NER  \\\n",
       "movie_id                                                      \n",
       "975900    {Mars, Desolation Williams Arriving, Sergeant ...   \n",
       "261236                      {Johns, Eva, Yvonne Eva, Chris}   \n",
       "171005          {Catherine, Henry V, Plot, Henry, Henry VI}   \n",
       "\n",
       "                                               no_stopwords  \\\n",
       "movie_id                                                      \n",
       "975900    [second, half, 22nd, century, film, depicts, p...   \n",
       "261236    [upper, class, housewife, becomes, frustrated,...   \n",
       "171005    [dateact, 1act, 2act, 3act, 4act, 5, negotiati...   \n",
       "\n",
       "                                                 lemmatized  \n",
       "movie_id                                                     \n",
       "975900    [second, half, 22nd, century, film, depicts, p...  \n",
       "261236    [upper, class, housewife, becomes, frustrated,...  \n",
       "171005    [dateact, 1act, 2act, 3act, 4act, 5, negotiati...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize\n",
    "movies_with_plot_df[\"lemmatized\"] = movies_with_plot_df[\"no_stopwords\"].apply(\n",
    "    lambda l: [lemmatizer.lemmatize(s) for s in l])\n",
    "movies_with_plot_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a7115",
   "metadata": {},
   "source": [
    "#### BOW creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adb6e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW = set()\n",
    "for row_id, row_data in movies_with_plot_df[\"lemmatized\"].apply(lambda l: set(l)).iteritems():\n",
    "    BOW = BOW.union(row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0bb53",
   "metadata": {},
   "source": [
    "#### BOW Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e73229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BOW_mapping(words_list: list, BOW_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Map the BOW for each plot to its encoding in row id and number of occurences.\n",
    "    \n",
    "    :param words_list: List of the words contained in the plot (BOW).\n",
    "    :param BOW_dict: Dictionnary containing the mapping between words and ids in the BOW matrix.\n",
    "    \n",
    "    :return: The dictionnary with the ids of each words and their number of occurences.\n",
    "    \n",
    "    \"\"\"\n",
    "    movie_mapping = dict()\n",
    "    for w in words_list:\n",
    "        word_id = BOW_dict[w]\n",
    "        if word_id not in movie_mapping:\n",
    "            movie_mapping[word_id] = 1\n",
    "        else:\n",
    "            movie_mapping[word_id] += 1 \n",
    "    return movie_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f63cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_dict = dict(zip(BOW,range(len(BOW))))\n",
    "reversed_BOW_dict = {v:k for k,v in BOW_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dda5e944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>NER</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>{Mars, Desolation Williams Arriving, Sergeant ...</td>\n",
       "      <td>[second, half, 22nd, century, film, depicts, p...</td>\n",
       "      <td>[second, half, 22nd, century, film, depicts, p...</td>\n",
       "      <td>{46177: 2, 39247: 1, 36246: 1, 30102: 1, 24263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, an, upper, class, housewife, becomes, fr...</td>\n",
       "      <td>{Johns, Eva, Yvonne Eva, Chris}</td>\n",
       "      <td>[upper, class, housewife, becomes, frustrated,...</td>\n",
       "      <td>[upper, class, housewife, becomes, frustrated,...</td>\n",
       "      <td>{74718: 1, 39687: 1, 24551: 1, 25685: 2, 64523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171005</th>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...</td>\n",
       "      <td>{Catherine, Henry V, Plot, Henry, Henry VI}</td>\n",
       "      <td>[dateact, 1act, 2act, 3act, 4act, 5, negotiati...</td>\n",
       "      <td>[dateact, 1act, 2act, 3act, 4act, 5, negotiati...</td>\n",
       "      <td>{26547: 1, 26646: 1, 67202: 1, 69231: 1, 60390...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       plot  \\\n",
       "movie_id                                                      \n",
       "975900    Set in the second half of the 22nd century, th...   \n",
       "261236    Eva, an upper class housewife, becomes frustra...   \n",
       "171005    {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...   \n",
       "\n",
       "                                                  tokenized  \\\n",
       "movie_id                                                      \n",
       "975900    [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "261236    [Eva, an, upper, class, housewife, becomes, fr...   \n",
       "171005    [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...   \n",
       "\n",
       "                                                        NER  \\\n",
       "movie_id                                                      \n",
       "975900    {Mars, Desolation Williams Arriving, Sergeant ...   \n",
       "261236                      {Johns, Eva, Yvonne Eva, Chris}   \n",
       "171005          {Catherine, Henry V, Plot, Henry, Henry VI}   \n",
       "\n",
       "                                               no_stopwords  \\\n",
       "movie_id                                                      \n",
       "975900    [second, half, 22nd, century, film, depicts, p...   \n",
       "261236    [upper, class, housewife, becomes, frustrated,...   \n",
       "171005    [dateact, 1act, 2act, 3act, 4act, 5, negotiati...   \n",
       "\n",
       "                                                 lemmatized  \\\n",
       "movie_id                                                      \n",
       "975900    [second, half, 22nd, century, film, depicts, p...   \n",
       "261236    [upper, class, housewife, becomes, frustrated,...   \n",
       "171005    [dateact, 1act, 2act, 3act, 4act, 5, negotiati...   \n",
       "\n",
       "                                                   encoding  \n",
       "movie_id                                                     \n",
       "975900    {46177: 2, 39247: 1, 36246: 1, 30102: 1, 24263...  \n",
       "261236    {74718: 1, 39687: 1, 24551: 1, 25685: 2, 64523...  \n",
       "171005    {26547: 1, 26646: 1, 67202: 1, 69231: 1, 60390...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_plot_df[\"encoding\"] = movies_with_plot_df[\"lemmatized\"].apply(\n",
    "    lambda l: BOW_mapping(l,BOW_dict))\n",
    "movies_with_plot_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "57e67b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix representation\n",
    "number_of_words_per_movie = movies_with_plot_df[\"encoding\"].apply(len).reset_index()[\"encoding\"].values\n",
    "column_ids = np.array([i for i in range(len(number_of_words_per_movie)) \n",
    "                       for j in range(number_of_words_per_movie[i])])\n",
    "row_ids = movies_with_plot_df[\"encoding\"].apply(lambda d: list(d.keys()))\n",
    "row_ids = row_ids.reset_index()[\"encoding\"].agg(np.concatenate)\n",
    "data = movies_with_plot_df[\"encoding\"].apply(lambda d: list(d.values()))\n",
    "data = data.reset_index()[\"encoding\"].agg(np.concatenate)\n",
    "BOW_matrix = csr_matrix((data, (column_ids,row_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "172aaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "movies_with_plot_df.to_pickle(\"../../data/post_processing/plot_df.pkl\")\n",
    "save_npz(\"../../data/post_processing/BOW_matrix.npz\",BOW_matrix)\n",
    "with open(\"../../data/post_processing/BOW_mapping.pkl\", 'wb') as handle:\n",
    "    pickle.dump(BOW_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2e018",
   "metadata": {},
   "source": [
    "### Odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "326410e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_term_frequency(matrix: csr_matrix, epsilon=EPSILON, doc_freq=False, hard_clip=False):\n",
    "    \"\"\"\n",
    "    Compute the term frequency of words in the given BOW matrix.\n",
    "    \n",
    "    :param matrix: Scipy sparse BOW matrix.\n",
    "    :param epsilon: Smoothing parameter.\n",
    "    :param doc_freq: Indicator if the term frequency should be multiplied by the doc_freq.\n",
    "                     It gives more weights to terms that appear in many documents.\n",
    "    :param hard_clip: Indicator if the frequency in a term should be capped to 1.\n",
    "                     Similar to doc_freq, it avoid bias toward docs with lot of repetitions.\n",
    "    \n",
    "    :return: Numpy array containing the smoothed term frequency.\n",
    "    \"\"\"\n",
    "    tf = np.array(matrix.sum(axis=0).tolist()[0])\n",
    "    tf = (tf+EPSILON)/tf.sum()\n",
    "    if hard_clip:\n",
    "        capped_occurence = matrix.copy()\n",
    "        capped_occurence[capped_occurence>1] = 1\n",
    "        tf = np.array(capped_occurence.sum(axis=0).tolist()[0])\n",
    "        tf = (tf+EPSILON)/tf.sum()\n",
    "        return tf\n",
    "    elif doc_freq:\n",
    "        capped_occurence = matrix.copy()\n",
    "        capped_occurence[capped_occurence>1] = 1\n",
    "        doc_number = epsilon+np.array(capped_occurence.sum(axis=0).tolist()[0])\n",
    "        return doc_number*tf\n",
    "    else:\n",
    "        return tf\n",
    "    \n",
    "def get_top_k_terms(tf_popular: np.array, tf_unpopular: np.array,\n",
    "                    reversed_BOW_dictionnary: dict, k=30,\n",
    "                    bad_movie=False):\n",
    "    \"\"\"\n",
    "    Print the terms with the highest or lowest odd ratio in the data.\n",
    "    \n",
    "    :param tf_popular: Term frequency for popular movies.\n",
    "    :param tf_unpopular: Term frequency for unpopular movies.\n",
    "    :param reversed_BOW_dictionnary: Dictionnary of term index with word string.\n",
    "    :param k: Number of terms to retrieve.\n",
    "    :param bad_movie: Indicator if should return the lowest log odds, so best term for bad movies.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Log odds\n",
    "    log_odds = np.log(tf_popular/tf_unpopular)\n",
    "    if bad_movie:\n",
    "        log_odds = -log_odds\n",
    "    top_k_ids = np.argpartition(log_odds, -k)[-k:]\n",
    "    top_log_odds = sorted([(idx,log_odds[idx]) for idx in top_k_ids],key=lambda l: -l[1])\n",
    "    print(f\"The top {k} terms with the highest log odds are:\")\n",
    "    for idx, value in top_log_odds:\n",
    "        print(f\"\\t-{reversed_BOW_dict[idx]}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecbbbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_row_ids = (movies_with_plot_df.merge(movie_regression_df[\"average_rating\"],how=\"left\",on=\"movie_id\"\n",
    "                         ).reset_index()[\"average_rating\"] > SUCCESS_THRESHOLD).values\n",
    "unpopular_row_ids = ~popular_row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db63568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative is to do an harder filtering on the movies we want to consider rather than simple\n",
    "# one sided threshold.\n",
    "popular_row_ids = (movies_with_plot_df.merge(movie_regression_df[\"average_rating\"],how=\"left\",on=\"movie_id\"\n",
    "                         ).reset_index()[\"average_rating\"] > 8.5).values\n",
    "unpopular_row_ids = (movies_with_plot_df.merge(movie_regression_df[\"average_rating\"],how=\"left\",on=\"movie_id\"\n",
    "                         ).reset_index()[\"average_rating\"] < 4.5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d50d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency for popular movies with smoothing term\n",
    "tf_popular_movies = compute_term_frequency(BOW_matrix[popular_row_ids,:],\n",
    "                                           doc_freq=False,hard_clip=False)\n",
    "# Term frequecy for unpopular movies with smoothing term\n",
    "tf_unpopular_movies = compute_term_frequency(BOW_matrix[unpopular_row_ids,:],\n",
    "                                             doc_freq=False,hard_clip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4cdce4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 terms with the highest log odds are:\n",
      "\t-alien: 12.129503607433069\n",
      "\t-scientist: 12.007336038430578\n",
      "\t-monster: 11.787013502711522\n",
      "\t-strange: 11.772828877779922\n",
      "\t-zombie: 11.456159534561106\n",
      "\t-vampire: 11.330996522325917\n",
      "\t-base: 11.308523691726355\n",
      "\t-wood: 11.29709500896437\n",
      "\t-shark: 11.225636130124736\n",
      "\t-unfortunately: 11.213213625558257\n",
      "\t-animal: 11.200634859174164\n",
      "\t-experiment: 11.148675187753913\n",
      "\t-lab: 11.121646551895624\n",
      "\t-box: 11.121646551895624\n",
      "\t-stab: 11.079682411504924\n",
      "\t-underground: 11.05069491664842\n",
      "\t-talking: 11.05069491664842\n",
      "\t-mask: 11.035879852812323\n",
      "\t-expedition: 11.02084199806195\n",
      "\t-jungle: 10.925531969772537\n",
      "\t-california: 10.908724879704694\n",
      "\t-treasure: 10.891630475568022\n",
      "\t-robot: 10.874238763104135\n",
      "\t-dad: 10.874238763104135\n",
      "\t-drink: 10.856539217333\n",
      "\t-investigation: 10.838520744297794\n",
      "\t-castle: 10.838520744297794\n",
      "\t-sequence: 10.801479541227952\n",
      "\t-sheriff: 10.801479541227952\n",
      "\t-helicopter: 10.78243138254166\n"
     ]
    }
   ],
   "source": [
    "get_top_k_terms(tf_popular_movies,tf_unpopular_movies,reversed_BOW_dict,k=30,bad_movie=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e6ca6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log odds\n",
    "log_odds = np.log(tf_popular_movies/tf_unpopular_movies)\n",
    "# Plot\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "fig.suptitle(\"Plot of log odds of term frequency in popular and unpopular movies\")\n",
    "ax.set_xlabel(\"log_odds\")\n",
    "ax.set_yscale(\"log\")\n",
    "sns.histplot(log_odds,ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9aea28",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2a2b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=10)\n",
    "LDA_fit = LDA.fit(BOW_matrix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f07c184c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come 5969.911938868805\n",
      "day 6749.735487782101\n",
      "take 6779.377176953765\n",
      "family 6907.497020138551\n",
      "home 7100.591097318871\n",
      "mother 7234.467914431654\n",
      "find 7645.739714186616\n",
      "one 7498.925054895799\n",
      "life 8217.65464943453\n",
      "friend 7659.558152995464\n",
      "tell 8721.644199531542\n",
      "go 9286.438289482943\n",
      "father 9062.916548656569\n",
      "love 9410.643344394572\n",
      "get 10259.973487622008\n",
      "\n",
      "\n",
      " name                           Alexander's Ragtime Band\n",
      "release_date                        1938-08-16 00:00:00\n",
      "revenue                                       3600000.0\n",
      "runtime                                           106.0\n",
      "average_rating                                      6.9\n",
      "num_votes                                          2160\n",
      "North America and Australia                         1.0\n",
      "Western Europe                                      0.0\n",
      "Asia                                                0.0\n",
      "Africa and Middle-East                              0.0\n",
      "Eastern Europe and Russia                           0.0\n",
      "Central and South America                           0.0\n",
      "actor_number                                        4.0\n",
      "mean_actor_age                                    26.75\n",
      "gender_ratio                                        0.0\n",
      "has_famous_actor                                    0.0\n",
      "action                                              0.0\n",
      "adventure                                           0.0\n",
      "comedy                                              1.0\n",
      "drama                                               0.0\n",
      "thriller                                            0.0\n",
      "horror                                              0.0\n",
      "animation                                           0.0\n",
      "children                                            0.0\n",
      "adult                                               0.0\n",
      "fantasy                                             0.0\n",
      "genre                                               0.0\n",
      "genre_number                                        3.0\n",
      "has_common_language                                 1.0\n",
      "language_number                                     1.0\n",
      "has_common_character_name                           0.0\n",
      "character_number                                    1.0\n",
      "decade                                             1930\n",
      "title_length                                          3\n",
      "combinned_movie_num                                18.0\n",
      "combinned_best_rating                               7.4\n",
      "num_directors                                       1.0\n",
      "combinned_movie_success                               0\n",
      "Name: 10408933, dtype: object\n",
      "\n",
      "\n",
      "        movie_id       genre_name\n",
      "14606  10408933          musical\n",
      "59831  10408933           comedy\n",
      "98175  10408933  black-and-white\n"
     ]
    }
   ],
   "source": [
    "words_nb = 15\n",
    "test_movie_id = 3\n",
    "test_movie = BOW_matrix[test_movie_id,:].reshape(1,len(BOW_dict))\n",
    "topic = np.argmax(LDA_fit.transform(test_movie))\n",
    "top_words_ids = np.argpartition(LDA_fit.components_[topic,:], -words_nb)[-words_nb:]\n",
    "for word_id in top_words_ids:\n",
    "    print(list(BOW_dict)[word_id], LDA_fit.components_[topic,word_id])\n",
    "print(\"\\n\\n\",movie_regression_df.loc[movie_regression_df.index[test_movie_id]])\n",
    "print(\"\\n\\n\",is_of_type_df[is_of_type_df[\"movie_id\"] == movie_regression_df.index[test_movie_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730772a",
   "metadata": {},
   "source": [
    "## Add term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b3fab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_to_regression(regression_dataframe: pd.DataFrame,\n",
    "                           plot_dataframe: pd.DataFrame,\n",
    "                           word: str, BOW_dict: dict, binarize=True):\n",
    "    \"\"\"\n",
    "    Add the occurence of the given term as a feature in the regression dataframe.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    :param plot_dataframe: Pandas DataFrame with the plot processing data.\n",
    "    :param word: Word to integrate in the regression dataframe.\n",
    "    :param BOW_dict: Dictionnary containing the mapping between words and ids in the BOW matrix.\n",
    "    :param binarize: Indicator if the output should be a single binary variable for the \n",
    "                    occurence of the word in the movie rather than the number of occurences\n",
    "    \n",
    "    \"\"\"\n",
    "    movie_has_term_series = plot_dataframe[\"encoding\"].apply(\n",
    "        lambda bow: bow[BOW_dict[word]] if BOW_dict[word] in bow else 0)\n",
    "    if binarize:\n",
    "        movie_has_term_series = movie_has_term_series > 0\n",
    "    regression_dataframe[f\"plot_has_{word}\"] = movie_has_term_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b1c5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = movie_regression_df.copy()\n",
    "add_word_to_regression(a, movies_with_plot_df, \"underground\", BOW_dict, binarize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f2491",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fba07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column(dataframe: pd.DataFrame, col_name: str):\n",
    "    \"\"\"\n",
    "    Standardize the given column in the provided dataframe.\n",
    "    \n",
    "    :param dataframe: Pandas DataFrame containing the data.\n",
    "    :param col_name: Name of the column to standardize.\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe[col_name] = (dataframe[col_name]-\n",
    "        dataframe[col_name].mean())/dataframe[col_name].std()\n",
    "    \n",
    "def process_dataframe(dataframe: pd.DataFrame,\n",
    "                      parameters={\"drop\": [], \"nan_filtering\":[\"all\"],\"decades\":[],\n",
    "                                  \"log\":[], \"standardize\":[]}) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pre-process the dataframe for regression given the instructions in parameters.\n",
    "    \n",
    "    :param dataframe: Pandas DataFrame with the movie data for regression\n",
    "    :param parameters: Dictionnary with the different parameters for pre-processing:\n",
    "                            - drop: List of columns to drop.\n",
    "                            - nan_filtering: List of columns where nan rows should be excluded.\n",
    "                            - decades: List of decades to keep. If empty, keep all decades.\n",
    "                            - log: List of columns to log transform.\n",
    "                            - standardize: List of columns to standardize.\n",
    "                    \n",
    "    \n",
    "    :return: Processed Pandas DataFrame ready for regression.\n",
    "    \n",
    "    \"\"\"\n",
    "    regression_df = dataframe.copy()\n",
    "    # Filter out columns\n",
    "    regression_df = regression_df.drop(parameters[\"drop\"],axis=1)\n",
    "    # Filter out decades\n",
    "    if len(parameters[\"decades\"]) != 0:\n",
    "        regression_df = regression_df[\n",
    "            regression_df[\"decade\"].isin(parameters[\"decades\"])]\n",
    "    # Filter out NaN\n",
    "    if len(parameters[\"nan_filtering\"]) != 0:\n",
    "        if parameters[\"nan_filtering\"][0] == \"all\":\n",
    "            regression_df = regression_df.dropna(how=\"any\")\n",
    "        else:\n",
    "            regression_df = regression_df.dropna(subset=parameters[\"nan_filtering\"])\n",
    "    # Transform\n",
    "    for col in parameters[\"log\"]:\n",
    "        regression_df[\"log_\"+col] = regression_df[col].apply(np.log)\n",
    "    # Standardize\n",
    "    for col in parameters[\"standardize\"]:\n",
    "        standardize_column(regression_df,col)\n",
    "    return regression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23888ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_feature(regression_df: pd.DataFrame, target: pd.Series,\n",
    "                        current_features=[], ignored_features=[], \n",
    "                        alpha=0.05, show=False, log_reg=False) -> str:\n",
    "    \"\"\"\n",
    "    Report the best feature to integrate to the current OLS model based on r-squared.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    :param target: Pandas Series representing the target values.\n",
    "    :param current_features: List of features integrated in the actual model.\n",
    "    :param ignored_features: List of features that should not be integrated in the regression.\n",
    "    :param alpha: Significance level, default 0.05.\n",
    "    :param show: Display the different features scores.\n",
    "    :param log_reg: Indicator to perform a logistic regression instead of linear regression.\n",
    "    \n",
    "    :result: Name of the best feature or None if no new significant features.\n",
    "    \n",
    "    \"\"\"\n",
    "    result_dict = {'predictor': [], \"aic\":[], \"p_value\":[]}\n",
    "    if not log_reg:\n",
    "        result_dict['r-squared'] = []\n",
    "    for col in regression_df.columns:\n",
    "        if col not in (current_features+ignored_features):\n",
    "            X = regression_df[current_features + [col]]\n",
    "            if log_reg:\n",
    "                model = sm.Logit(binary_target, sm.add_constant(X)).fit()\n",
    "            else:\n",
    "                model = sm.OLS(target, sm.add_constant(X)).fit()\n",
    "            #Add the column name to our dictionary\n",
    "            result_dict['predictor'].append(col)\n",
    "            if not log_reg:\n",
    "                #Calculate the r-squared value between the target and predicted target\n",
    "                r2 = model.rsquared\n",
    "                result_dict['r-squared'].append(r2)\n",
    "            #Add the model metrics to our dictionary\n",
    "            result_dict['aic'].append(model.aic)\n",
    "            result_dict['p_value'].append(model.pvalues.loc[col])\n",
    "    #Once it's iterated through every column, turn our dict into a sorted DataFrame\n",
    "    candidates_features = pd.DataFrame(result_dict).sort_values(by=['aic'],\n",
    "                                                          ascending = True)\n",
    "    if show:\n",
    "        display(candidates_features.head())\n",
    "        \n",
    "    candidates_features = candidates_features[candidates_features[\"p_value\"] < alpha]\n",
    "    if len(candidates_features) == 0:\n",
    "        return \"None\"\n",
    "    else:\n",
    "        return candidates_features[\"predictor\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a962f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(regression_df: pd.DataFrame, target: pd.Series,\n",
    "                        ignored_features=[], alpha=0.05, show=False,\n",
    "                        log_reg=False) -> list:\n",
    "    \"\"\"\n",
    "    Iterative forward feature selection based on r-squared without interaction terms.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    :param target: Pandas Series representing the target values.\n",
    "    :param current_features: List of features integrated in the actual model.\n",
    "    :param ignored_features: List of features that should not be integrated in the regression.\n",
    "    :param alpha: Significance level, default 0.05.\n",
    "    :param show: Display the different features scores.\n",
    "    :param log_reg: Indicator to perform a logistic regression instead of linear regression.\n",
    "    \n",
    "    :result: List of the best features to model the target.\n",
    "    \n",
    "    \"\"\"\n",
    "    last_feature = \"\"\n",
    "    current_features = []\n",
    "    while ((len(ignored_features) + len(current_features)) < len(regression_df)\n",
    "           and last_feature != \"None\"):\n",
    "        last_feature = select_next_feature(regression_df, target,\n",
    "                        current_features=current_features,\n",
    "                        ignored_features=ignored_features, \n",
    "                        alpha=alpha, show=show, log_reg=log_reg)\n",
    "        if last_feature != \"None\":\n",
    "            current_features.append(last_feature)\n",
    "    return current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "328d8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_VIF_dataframe(regression_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the VIF for each features in the given dataframe.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    \n",
    "    :return: Pandas DataFrame with the VIF for each features.\n",
    "    \n",
    "    \"\"\"\n",
    "    vif_features = regression_df.columns\n",
    "    vif_values = [variance_inflation_factor(regression_df.values, i) \n",
    "                for i in range(len(regression_df.columns))]\n",
    "    vif_df = pd.DataFrame(np.array([vif_features,vif_values]).T,columns=[\"predictor\",\"VIF\"])\n",
    "    return vif_df\n",
    "\n",
    "def filter_multicolinearity(regression_df: pd.DataFrame, threshold=5):\n",
    "    \"\"\"\n",
    "    Remove the features that shows high multicollinearity based on VIF.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    :param threshold: Threshold above which a VIF is considered to high to be kept. \n",
    "    \n",
    "    :return: Pandas DataFrame with data for regression without high multicollinearity.\n",
    "    \n",
    "    \"\"\"\n",
    "    new_regression_df = regression_df.copy()\n",
    "    vif_df = create_VIF_dataframe(new_regression_df)\n",
    "    high_VIF = (vif_df[\"VIF\"] > threshold).sum()\n",
    "    while high_VIF:\n",
    "        highest_VIF_predictor = vif_df.iloc[\n",
    "            vif_df[\"VIF\"].astype(np.float32).argmax()][\"predictor\"]\n",
    "        new_regression_df = new_regression_df.drop(highest_VIF_predictor,axis=1)\n",
    "        vif_df = create_VIF_dataframe(new_regression_df)\n",
    "        high_VIF = (vif_df[\"VIF\"] > threshold).sum()\n",
    "    return new_regression_df, vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77e6186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_regression_df(dataframe: pd.DataFrame, decades: list,\n",
    "                         parameters=DEFAULT_PARAMETERS, target_threshold=SUCCESS_THRESHOLD,\n",
    "                         bad_movies=False) -> tuple:\n",
    "    \"\"\"\n",
    "    Process the dataframe for regression and creates targets and weights vectors.\n",
    "    \n",
    "    :param dataframe: Pandas DataFrame containing the data for regression.\n",
    "    :param decades: List of decades to integrate for regression. \n",
    "                    If empty then all decades will be considered.\n",
    "    :param parameters: Parameter dictionnary to process the dataframe.\n",
    "    :param target_threshold: Threshold from which we consider a movie as successful.\n",
    "      \n",
    "    :return: Tuple with the regression DataFrame, the raw and binary targets and the number of votes.\n",
    "    \"\"\"\n",
    "    parameters[\"decades\"] = decades\n",
    "    processed_df = process_dataframe(dataframe,parameters)\n",
    "    # Extract target and associated features.\n",
    "    target, num_votes= processed_df[\"average_rating\"], processed_df[\"num_votes\"]\n",
    "    binary_target = target.copy()\n",
    "    binary_target[binary_target<target_threshold] = 0\n",
    "    binary_target[binary_target>=target_threshold] = 1\n",
    "    if bad_movies:\n",
    "        binary_target = 1-binary_target\n",
    "    # Remove Unecessary Columns.\n",
    "    processed_df = processed_df.drop(parameters[\"post_drop\"],axis=1)\n",
    "    processed_df, vif_df = filter_multicolinearity(processed_df)\n",
    "    return processed_df, target, binary_target, num_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa7ffcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df, target, binary_target, num_votes = format_regression_df(movie_regression_df,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f58d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = forward_selection(processed_df, target, ignored_features=[],\n",
    "                             alpha=0.05, show=False, log_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2ed6640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(target, sm.add_constant(processed_df[features])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dab1f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>average_rating</td>  <th>  R-squared:         </th> <td>   0.169</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.168</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   209.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 18 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:48:36</td>     <th>  Log-Likelihood:    </th> <td> -25939.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 19572</td>      <th>  AIC:               </th> <td>5.192e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 19552</td>      <th>  BIC:               </th> <td>5.208e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                     <td>    5.8382</td> <td>    0.019</td> <td>  305.144</td> <td> 0.000</td> <td>    5.801</td> <td>    5.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>combinned_movie_success</th>   <td>    0.4894</td> <td>    0.014</td> <td>   33.767</td> <td> 0.000</td> <td>    0.461</td> <td>    0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drama</th>                     <td>    0.3139</td> <td>    0.015</td> <td>   21.095</td> <td> 0.000</td> <td>    0.285</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horror</th>                    <td>   -0.3638</td> <td>    0.027</td> <td>  -13.612</td> <td> 0.000</td> <td>   -0.416</td> <td>   -0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Western Europe</th>            <td>    0.1703</td> <td>    0.015</td> <td>   11.086</td> <td> 0.000</td> <td>    0.140</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>animation</th>                 <td>    0.5915</td> <td>    0.054</td> <td>   10.988</td> <td> 0.000</td> <td>    0.486</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fantasy</th>                   <td>   -0.2285</td> <td>    0.024</td> <td>   -9.642</td> <td> 0.000</td> <td>   -0.275</td> <td>   -0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_number</th>              <td>    0.0152</td> <td>    0.001</td> <td>   12.219</td> <td> 0.000</td> <td>    0.013</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Asia</th>                      <td>    0.1652</td> <td>    0.019</td> <td>    8.811</td> <td> 0.000</td> <td>    0.128</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Eastern Europe and Russia</th> <td>    0.3400</td> <td>    0.043</td> <td>    7.900</td> <td> 0.000</td> <td>    0.256</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adult</th>                     <td>   -0.4737</td> <td>    0.059</td> <td>   -8.004</td> <td> 0.000</td> <td>   -0.590</td> <td>   -0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>action</th>                    <td>   -0.1021</td> <td>    0.019</td> <td>   -5.292</td> <td> 0.000</td> <td>   -0.140</td> <td>   -0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>children</th>                  <td>   -0.1478</td> <td>    0.027</td> <td>   -5.408</td> <td> 0.000</td> <td>   -0.201</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comedy</th>                    <td>   -0.0993</td> <td>    0.015</td> <td>   -6.498</td> <td> 0.000</td> <td>   -0.129</td> <td>   -0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre</th>                     <td>    0.1256</td> <td>    0.022</td> <td>    5.760</td> <td> 0.000</td> <td>    0.083</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_ratio</th>              <td>   -0.0821</td> <td>    0.016</td> <td>   -5.004</td> <td> 0.000</td> <td>   -0.114</td> <td>   -0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adventure</th>                 <td>   -0.0691</td> <td>    0.021</td> <td>   -3.349</td> <td> 0.001</td> <td>   -0.110</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thriller</th>                  <td>   -0.0458</td> <td>    0.015</td> <td>   -2.996</td> <td> 0.003</td> <td>   -0.076</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>              <td>    0.0166</td> <td>    0.007</td> <td>    2.504</td> <td> 0.012</td> <td>    0.004</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Central and South America</th> <td>    0.1208</td> <td>    0.059</td> <td>    2.050</td> <td> 0.040</td> <td>    0.005</td> <td>    0.236</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2254.537</td> <th>  Durbin-Watson:     </th> <td>   1.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3840.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.795</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.477</td>  <th>  Cond. No.          </th> <td>    97.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         average_rating   R-squared:                       0.169\n",
       "Model:                            OLS   Adj. R-squared:                  0.168\n",
       "Method:                 Least Squares   F-statistic:                     209.2\n",
       "Date:                Sun, 18 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        10:48:36   Log-Likelihood:                -25939.\n",
       "No. Observations:               19572   AIC:                         5.192e+04\n",
       "Df Residuals:                   19552   BIC:                         5.208e+04\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================\n",
       "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "const                         5.8382      0.019    305.144      0.000       5.801       5.876\n",
       "combinned_movie_success       0.4894      0.014     33.767      0.000       0.461       0.518\n",
       "drama                         0.3139      0.015     21.095      0.000       0.285       0.343\n",
       "horror                       -0.3638      0.027    -13.612      0.000      -0.416      -0.311\n",
       "Western Europe                0.1703      0.015     11.086      0.000       0.140       0.200\n",
       "animation                     0.5915      0.054     10.988      0.000       0.486       0.697\n",
       "fantasy                      -0.2285      0.024     -9.642      0.000      -0.275      -0.182\n",
       "actor_number                  0.0152      0.001     12.219      0.000       0.013       0.018\n",
       "Asia                          0.1652      0.019      8.811      0.000       0.128       0.202\n",
       "Eastern Europe and Russia     0.3400      0.043      7.900      0.000       0.256       0.424\n",
       "adult                        -0.4737      0.059     -8.004      0.000      -0.590      -0.358\n",
       "action                       -0.1021      0.019     -5.292      0.000      -0.140      -0.064\n",
       "children                     -0.1478      0.027     -5.408      0.000      -0.201      -0.094\n",
       "comedy                       -0.0993      0.015     -6.498      0.000      -0.129      -0.069\n",
       "genre                         0.1256      0.022      5.760      0.000       0.083       0.168\n",
       "gender_ratio                 -0.0821      0.016     -5.004      0.000      -0.114      -0.050\n",
       "adventure                    -0.0691      0.021     -3.349      0.001      -0.110      -0.029\n",
       "thriller                     -0.0458      0.015     -2.996      0.003      -0.076      -0.016\n",
       "title_length                  0.0166      0.007      2.504      0.012       0.004       0.030\n",
       "Central and South America     0.1208      0.059      2.050      0.040       0.005       0.236\n",
       "==============================================================================\n",
       "Omnibus:                     2254.537   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3840.812\n",
       "Skew:                          -0.795   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.477   Cond. No.                         97.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26ce4e",
   "metadata": {},
   "source": [
    "## Decade pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_results = dict()\n",
    "for decade in movie_regression_df[\"decade\"].value_counts().head(11).index:\n",
    "    processed_df, target, binary_target, num_votes = format_regression_df(movie_regression_df,[decade])\n",
    "    features = forward_selection(processed_df, target, ignored_features=[], alpha=0.05, show=False)\n",
    "    model = sm.OLS(target, sm.add_constant(processed_df)).fit()\n",
    "    decade_results[decade] = model.rsquared\n",
    "decade_results_df = pd.DataFrame(decade_results.values(),index=decade_results.keys(),\n",
    "                                columns=[\"r-squared\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58b4c1",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ba217a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = sm.GLM(binary_target, sm.add_constant(process_df[current_features]),\n",
    "               family=sm.families.Binomial(link=sm.families.links.logit())).fit_regularized(\n",
    "                alpha=0.001,L1_wt=0)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f66d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316208\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.312218\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316448\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.314520\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316414\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.311116\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316045\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316326\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316452\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316038\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.314968\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.307282\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316428\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.315064\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.315846\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316472\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316177\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316544\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.314124\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316435\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316370\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.316552\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296116\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295663\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.292954\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295980\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.294521\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295916\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.291897\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295583\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296031\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296093\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295837\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.294925\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289752\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296047\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295446\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295465\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296110\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295810\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296116\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.293416\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296071\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.291902\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295985\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289503\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286845\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289683\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.288546\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289624\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286195\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.288935\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289686\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289736\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289735\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289476\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289693\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289607\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.288688\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289749\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289348\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289586\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.288014\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289751\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286236\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289682\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286013\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282314\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286110\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284881\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286057\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.285577\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286163\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286190\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286050\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.285570\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.285977\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.285992\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.285418\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286159\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.285800\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286183\n",
      "         Iterations 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284864\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286194\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.283057\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286097\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.281479\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282174\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280515\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282080\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.281528\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282250\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282307\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282219\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.281940\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282206\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282108\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.281643\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282298\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.281916\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282295\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280611\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282219\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280171\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282229\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.279665\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280082\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278790\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280006\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.279301\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280118\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280170\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280132\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.279723\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280037\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.279937\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.279644\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280146\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.279729\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280168\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278774\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280019\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280169\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278327\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278674\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277266\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278626\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277790\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278731\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278765\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278756\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278183\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278643\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278495\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278190\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278765\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278231\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278772\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278624\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.278770\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276837\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277163\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277090\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276372\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277244\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277261\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277255\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276714\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277180\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276975\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276676\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277261\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276744\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277264\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277120\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277261\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275931\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276268\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276190\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276347\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276337\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276279\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275932\n",
      "         Iterations 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276223\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276111\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275785\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276370\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275915\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276372\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276225\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276368\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275309\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275677\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275599\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275761\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275756\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275624\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275329\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275675\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275532\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275697\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275335\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275753\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275655\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275727\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275214\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275148\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275294\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275290\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275171\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274896\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275197\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275051\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275238\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274807\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275275\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275194\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275248\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274718\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274655\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274790\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274786\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274662\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274368\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274712\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274557\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274730\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274775\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274693\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274745\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274288\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274231\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274349\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274307\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274163\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274175\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274043\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274322\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274320\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274233\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274301\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273968\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273901\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274022\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273984\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273823\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273898\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273993\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274037\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273915\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273982\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273747\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273683\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273806\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273823\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273692\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273789\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273823\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273681\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273762\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273597\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273544\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273667\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273680\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273565\n",
      "         Iterations 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273641\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273681\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273620\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273458\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273533\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273544\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273430\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273508\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273544\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273479\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273349\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273420\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273425\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273383\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273430\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273358\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "features = forward_selection(processed_df, binary_target, ignored_features=[],\n",
    "                             alpha=0.05, show=False, log_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83eb9d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273430\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>average_rating</td>  <th>  No. Observations:  </th>  <td> 19572</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 19554</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 18 Dec 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.1362</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:49:28</td>     <th>  Log-Likelihood:    </th> <td> -5351.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -6195.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                     <td>   -3.9590</td> <td>    0.092</td> <td>  -42.820</td> <td> 0.000</td> <td>   -4.140</td> <td>   -3.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>combinned_movie_success</th>   <td>    1.3606</td> <td>    0.055</td> <td>   24.585</td> <td> 0.000</td> <td>    1.252</td> <td>    1.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drama</th>                     <td>    0.6258</td> <td>    0.065</td> <td>    9.639</td> <td> 0.000</td> <td>    0.499</td> <td>    0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_number</th>              <td>    0.0550</td> <td>    0.004</td> <td>   12.777</td> <td> 0.000</td> <td>    0.047</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Asia</th>                      <td>    0.8377</td> <td>    0.066</td> <td>   12.640</td> <td> 0.000</td> <td>    0.708</td> <td>    0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>combinned_movie_num</th>       <td>   -0.0163</td> <td>    0.003</td> <td>   -6.171</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre</th>                     <td>    0.6443</td> <td>    0.073</td> <td>    8.864</td> <td> 0.000</td> <td>    0.502</td> <td>    0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Eastern Europe and Russia</th> <td>    0.9194</td> <td>    0.122</td> <td>    7.525</td> <td> 0.000</td> <td>    0.680</td> <td>    1.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_ratio</th>              <td>   -0.4079</td> <td>    0.070</td> <td>   -5.794</td> <td> 0.000</td> <td>   -0.546</td> <td>   -0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>animation</th>                 <td>    0.8311</td> <td>    0.157</td> <td>    5.281</td> <td> 0.000</td> <td>    0.523</td> <td>    1.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Western Europe</th>            <td>    0.2447</td> <td>    0.060</td> <td>    4.078</td> <td> 0.000</td> <td>    0.127</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adult</th>                     <td>   -1.3553</td> <td>    0.370</td> <td>   -3.659</td> <td> 0.000</td> <td>   -2.081</td> <td>   -0.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comedy</th>                    <td>   -0.3118</td> <td>    0.062</td> <td>   -5.042</td> <td> 0.000</td> <td>   -0.433</td> <td>   -0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horror</th>                    <td>   -0.4289</td> <td>    0.133</td> <td>   -3.229</td> <td> 0.001</td> <td>   -0.689</td> <td>   -0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adventure</th>                 <td>   -0.2006</td> <td>    0.069</td> <td>   -2.895</td> <td> 0.004</td> <td>   -0.336</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>              <td>    0.0566</td> <td>    0.026</td> <td>    2.218</td> <td> 0.027</td> <td>    0.007</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Central and South America</th> <td>    0.4758</td> <td>    0.198</td> <td>    2.397</td> <td> 0.017</td> <td>    0.087</td> <td>    0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thriller</th>                  <td>   -0.1277</td> <td>    0.061</td> <td>   -2.104</td> <td> 0.035</td> <td>   -0.247</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:         average_rating   No. Observations:                19572\n",
       "Model:                          Logit   Df Residuals:                    19554\n",
       "Method:                           MLE   Df Model:                           17\n",
       "Date:                Sun, 18 Dec 2022   Pseudo R-squ.:                  0.1362\n",
       "Time:                        10:49:28   Log-Likelihood:                -5351.6\n",
       "converged:                       True   LL-Null:                       -6195.7\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "=============================================================================================\n",
       "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "const                        -3.9590      0.092    -42.820      0.000      -4.140      -3.778\n",
       "combinned_movie_success       1.3606      0.055     24.585      0.000       1.252       1.469\n",
       "drama                         0.6258      0.065      9.639      0.000       0.499       0.753\n",
       "actor_number                  0.0550      0.004     12.777      0.000       0.047       0.063\n",
       "Asia                          0.8377      0.066     12.640      0.000       0.708       0.968\n",
       "combinned_movie_num          -0.0163      0.003     -6.171      0.000      -0.021      -0.011\n",
       "genre                         0.6443      0.073      8.864      0.000       0.502       0.787\n",
       "Eastern Europe and Russia     0.9194      0.122      7.525      0.000       0.680       1.159\n",
       "gender_ratio                 -0.4079      0.070     -5.794      0.000      -0.546      -0.270\n",
       "animation                     0.8311      0.157      5.281      0.000       0.523       1.140\n",
       "Western Europe                0.2447      0.060      4.078      0.000       0.127       0.362\n",
       "adult                        -1.3553      0.370     -3.659      0.000      -2.081      -0.629\n",
       "comedy                       -0.3118      0.062     -5.042      0.000      -0.433      -0.191\n",
       "horror                       -0.4289      0.133     -3.229      0.001      -0.689      -0.169\n",
       "adventure                    -0.2006      0.069     -2.895      0.004      -0.336      -0.065\n",
       "title_length                  0.0566      0.026      2.218      0.027       0.007       0.107\n",
       "Central and South America     0.4758      0.198      2.397      0.017       0.087       0.865\n",
       "thriller                     -0.1277      0.061     -2.104      0.035      -0.247      -0.009\n",
       "=============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(binary_target, sm.add_constant(processed_df[features])).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5e78e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Logistic Regression models with all features gives us 58 true positives.\n"
     ]
    }
   ],
   "source": [
    "tp = binary_target[model.predict(sm.add_constant(processed_df[features])) > 0.5].sum()\n",
    "print(f\"The Logistic Regression models with all features gives us {tp:.0f} true positives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf1764",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4e325",
   "metadata": {},
   "source": [
    "### Weighted Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eda3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_num_votes = np.log(num_votes)\n",
    "weights = 1+(log_num_votes-log_num_votes.min())/(log_num_votes.max()-log_num_votes.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25169be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(process_df, target,\n",
    "         weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5da75d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492bc01",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4294f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e401f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = process_df.copy()\n",
    "tmp_df[\"target\"] = binary_target.copy()\n",
    "train, test = train_test_split(tmp_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2041a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "_ = clf.fit(train.drop(\"target\",axis=1), train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test.drop(\"target\",axis=1))\n",
    "score = metrics.f1_score(test[\"target\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e92e1",
   "metadata": {},
   "source": [
    "## Advanced Tasks\n",
    "\n",
    "- Compute centrality of directors and actors instead of #movies\n",
    "- Subset on plot and extract NLP features --> odds ratio of terms / LDA and topic association (decorelation with genre)\n",
    "- Matrix factorization for value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95125fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b2c13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "B.add_nodes_from(set(appears_in_df[\"actor_id\"]), bipartite=0)\n",
    "B.add_nodes_from(set(appears_in_df[\"movie_id\"]), bipartite=1)\n",
    "actor_movie_edges = list(zip(appears_in_df[\"actor_id\"],appears_in_df[\"movie_id\"]))\n",
    "B.add_edges_from(actor_movie_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9166ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_nodes = {n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "movie_nodes = set(B) - top_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de2818bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_graph = nx.projected_graph(B,actor_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38a8560e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m actor_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mharmonic_centrality(actor_graph,actor_nodes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\networkx\\algorithms\\centrality\\harmonic.py:72\u001b[0m, in \u001b[0;36mharmonic_centrality\u001b[1;34m(G, nbunch, distance, sources)\u001b[0m\n\u001b[0;32m     70\u001b[0m centrality \u001b[38;5;241m=\u001b[39m {u: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m nbunch}\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m sources:\n\u001b[1;32m---> 72\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mspl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m nbunch\u001b[38;5;241m.\u001b[39mintersection(dist):\n\u001b[0;32m     74\u001b[0m         d \u001b[38;5;241m=\u001b[39m dist[u]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\generic.py:297\u001b[0m, in \u001b[0;36mshortest_path_length\u001b[1;34m(G, source, target, weight, method)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m# Find paths to all nodes accessible from the source.\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m         paths \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_source_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdijkstra\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m         path_length \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39msingle_source_dijkstra_path_length\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py:59\u001b[0m, in \u001b[0;36msingle_source_shortest_path_length\u001b[1;34m(G, source, cutoff)\u001b[0m\n\u001b[0;32m     57\u001b[0m     cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m nextlevel \u001b[38;5;241m=\u001b[39m {source: \u001b[38;5;241m1\u001b[39m}\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_single_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnextlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py:91\u001b[0m, in \u001b[0;36m_single_shortest_path_length\u001b[1;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m found:\n\u001b[1;32m---> 91\u001b[0m         nextlevel\u001b[38;5;241m.\u001b[39mupdate(adj[v])\n\u001b[0;32m     92\u001b[0m     level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m seen\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actor_centrality = nx.harmonic_centrality(actor_graph,actor_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ad415ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decade\n",
       "1890       1\n",
       "1900       5\n",
       "1910     124\n",
       "1920     432\n",
       "1930    1340\n",
       "1940    1503\n",
       "1950    1851\n",
       "1960    1858\n",
       "1970    2122\n",
       "1980    2973\n",
       "1990    3995\n",
       "2000    7791\n",
       "2010    2292\n",
       "2020       0\n",
       "Name: plot, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.merge(movie_regression_df[\"decade\"],on=\"movie_id\",how=\"left\").groupby(\"decade\")[\"plot\"].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
