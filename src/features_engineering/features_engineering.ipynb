{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b5181f",
   "metadata": {},
   "source": [
    "# Features Engineering\n",
    "\n",
    "Our data can be very high dimensional if we consider the number of languages, countries, actors etc. We have only 44k movies, but we have several hundreds on genres, languages and countries, which gives already around 10 millions possibilities. And this is without even looking at the hundreds of thousands of actors and characters. Thus we have to come up with features that can capture signal in the data, without having to do one-hot encoding for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07baa4a6",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d253e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Statistics\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.formula.api as smf\n",
    "# ML models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add51810",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4dc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINENT_ID = {\"North America and Australia\": [1,0,0,0,0,0],\n",
    "\"Central and South America\": [0,1,0,0,0,0],\n",
    "\"Western Europe\": [0,0,1,0,0,0],\n",
    "\"Eastern Europe and Russia\": [0,0,0,1,0,0],\n",
    "\"Africa and Middle-East\": [0,0,0,0,1,0],\n",
    "\"Asia\": [0,0,0,0,0,1]}\n",
    "\n",
    "COUNTRY_CONTINENT_MAPPING = {\n",
    "'afghanistan' : \"Africa and Middle-East\",\n",
    " 'albania' : \"Eastern Europe and Russia\",\n",
    " 'algeria' : \"Africa and Middle-East\",\n",
    " 'argentina': \"Central and South America\",\n",
    " 'armenia' : \"Africa and Middle-East\",\n",
    " 'aruba': \"Central and South America\",\n",
    " 'australia': \"North America and Australia\",\n",
    " 'austria': \"Western Europe\",\n",
    " 'azerbaijan' : \"Africa and Middle-East\",\n",
    " 'bahamas': \"Central and South America\",\n",
    " 'bahrain' : \"Africa and Middle-East\",\n",
    " 'bangladesh': \"Asia\",\n",
    " 'belgium': \"Western Europe\",\n",
    " 'bhutan': \"Asia\",\n",
    " 'bolivia': \"Central and South America\",\n",
    " 'bosnia and herzegovina' : \"Eastern Europe and Russia\",\n",
    " 'brazil': \"Central and South America\",\n",
    " 'bulgaria' : \"Eastern Europe and Russia\",\n",
    " 'burkina faso' : \"Africa and Middle-East\",\n",
    " 'burma': \"Asia\",\n",
    " 'cambodia': \"Asia\",\n",
    " 'cameroon' : \"Africa and Middle-East\",\n",
    " 'canada': \"North America and Australia\",\n",
    " 'chile': \"Central and South America\",\n",
    " 'china': \"Asia\",\n",
    " 'colombia': \"Central and South America\",\n",
    " 'congo' : \"Africa and Middle-East\",\n",
    " 'costa rica': \"Central and South America\",\n",
    " 'crime' : \"Eastern Europe and Russia\",\n",
    " 'croatia' : \"Eastern Europe and Russia\",\n",
    " 'cuba': \"Central and South America\",\n",
    " 'cyprus' : \"Eastern Europe and Russia\",\n",
    " 'czech republic' : \"Eastern Europe and Russia\",\n",
    " 'czechoslovakia' : \"Eastern Europe and Russia\",\n",
    " 'democratic republic of the congo' : \"Africa and Middle-East\",\n",
    " 'denmark': \"Western Europe\",\n",
    " 'egypt' : \"Africa and Middle-East\",\n",
    " 'estonia' : \"Eastern Europe and Russia\",\n",
    " 'ethiopia' : \"Africa and Middle-East\",\n",
    " 'finland': \"Western Europe\",\n",
    " 'france': \"Western Europe\",\n",
    " 'georgia' : \"Africa and Middle-East\",\n",
    " 'germany': \"Western Europe\",\n",
    " 'greece' : \"Eastern Europe and Russia\",\n",
    " 'haiti': \"Central and South America\",\n",
    " 'hong kong': \"Asia\",\n",
    " 'hungary' : \"Eastern Europe and Russia\",\n",
    " 'iceland': \"Western Europe\",\n",
    " 'india': \"Asia\",\n",
    " 'indonesia': \"Asia\",\n",
    " 'iran' : \"Africa and Middle-East\",\n",
    " 'iraq' : \"Africa and Middle-East\",\n",
    " 'iraqi kurdistan' : \"Africa and Middle-East\",\n",
    " 'ireland': \"Western Europe\",\n",
    " 'isle of man': \"Western Europe\",\n",
    " 'israel' : \"Africa and Middle-East\",\n",
    " 'italy': \"Western Europe\",\n",
    " 'jamaica': \"Central and South America\",\n",
    " 'japan': \"Asia\",\n",
    " 'jordan' : \"Africa and Middle-East\",\n",
    " 'kenya' : \"Africa and Middle-East\",\n",
    " 'korea': \"Asia\",\n",
    " 'kuwait' : \"Africa and Middle-East\",\n",
    " 'lebanon' : \"Africa and Middle-East\",\n",
    " 'libya' : \"Africa and Middle-East\",\n",
    " 'lithuania' : \"Eastern Europe and Russia\",\n",
    " 'luxembourg': \"Western Europe\",\n",
    " 'macau': \"Asia\",\n",
    " 'malaysia': \"Asia\",\n",
    " 'mali' : \"Africa and Middle-East\",\n",
    " 'malta': \"Western Europe\",\n",
    " 'mexico': \"Central and South America\",\n",
    " 'monaco': \"Western Europe\",\n",
    " 'mongolia': \"Asia\",\n",
    " 'montenegro' : \"Eastern Europe and Russia\",\n",
    " 'morocco' : \"Africa and Middle-East\",\n",
    " 'nepal': \"Asia\",\n",
    " 'netherlands': \"Western Europe\",\n",
    " 'new zealand': \"North America and Australia\",\n",
    " 'nigeria' : \"Africa and Middle-East\",\n",
    " 'norway': \"Western Europe\",\n",
    " 'pakistan' : \"Africa and Middle-East\",\n",
    " 'palestinian territories' : \"Africa and Middle-East\",\n",
    " 'panama': \"Central and South America\",\n",
    " 'peru': \"Central and South America\",\n",
    " 'philippines': \"Asia\",\n",
    " 'poland' : \"Eastern Europe and Russia\",\n",
    " 'portugal': \"Western Europe\",\n",
    " 'puerto rico': \"Central and South America\",\n",
    " 'republic of macedonia' : \"Eastern Europe and Russia\",\n",
    " 'romania' : \"Eastern Europe and Russia\",\n",
    " 'russia' : \"Eastern Europe and Russia\",\n",
    " 'senegal' : \"Africa and Middle-East\",\n",
    " 'serbia' : \"Eastern Europe and Russia\",\n",
    " 'serbia and montenegro' : \"Eastern Europe and Russia\",\n",
    " 'singapore': \"Asia\",\n",
    " 'slovakia' : \"Eastern Europe and Russia\",\n",
    " 'slovenia' : \"Eastern Europe and Russia\",\n",
    " 'south africa' : \"Africa and Middle-East\",\n",
    " 'south korea': \"Asia\",\n",
    " 'spain': \"Western Europe\",\n",
    " 'sri lanka': \"Asia\",\n",
    " 'sweden': \"Western Europe\",\n",
    " 'switzerland': \"Western Europe\",\n",
    " 'taiwan': \"Asia\",\n",
    " 'thailand': \"Asia\",\n",
    " 'tunisia' : \"Africa and Middle-East\",\n",
    " 'turkey' : \"Africa and Middle-East\",\n",
    " 'ukraine' : \"Eastern Europe and Russia\",\n",
    " 'united arab emirates' : \"Africa and Middle-East\",\n",
    " 'united kingdom': \"Western Europe\",\n",
    " 'united states of america': \"North America and Australia\",\n",
    " 'uruguay': \"Central and South America\",\n",
    " 'uzbekistan' : \"Africa and Middle-East\",\n",
    " 'venezuela': \"Central and South America\",\n",
    " 'vietnam': \"Asia\",\n",
    " 'yugoslavia' : \"Eastern Europe and Russia\",\n",
    " 'zambia' : \"Africa and Middle-East\",\n",
    " 'zimbabwe' : \"Africa and Middle-East\"\n",
    "}\n",
    "\n",
    "COUNTRY_ENCODING = { \n",
    "    \"North America and Australia\": [1,0,0,0,0,0],\n",
    "    \"Western Europe\":              [0,1,0,0,0,0],\n",
    "    \"Asia\":                        [0,0,1,0,0,0],\n",
    "    \"Africa and Middle-East\":      [0,0,0,1,0,0],\n",
    "    \"Eastern Europe and Russia\":   [0,0,0,0,1,0],\n",
    "    \"Central and South America\":   [0,0,0,0,0,1]\n",
    "}\n",
    "\n",
    "CONTINENT_LIST = [\"North America and Australia\",\"Western Europe\",\"Asia\",\n",
    "                  \"Africa and Middle-East\",\"Eastern Europe and Russia\", \n",
    "                  \"Central and South America\"]\n",
    "\n",
    "GENRE_MAPPING = {'absurdism': [\"comedy\"],\n",
    " 'acid western': [\"adventure\",\"action\"],\n",
    " 'action': [\"action\"],\n",
    " 'action comedy': [\"action\",\"comedy\"],\n",
    " 'action thrillers': [\"thriller\",\"action\"],\n",
    " 'action/adventure': [\"action\",\"adventure\"],\n",
    " 'addiction drama': [\"drama\"],\n",
    " 'adult': [\"adult\"],\n",
    " 'adventure': [\"adventure\"],\n",
    " 'adventure comedy': [\"adventure\",\"comedy\"],\n",
    " 'airplanes and airports': [\"other\"],\n",
    " 'albino bias': [\"drama\"],\n",
    " 'alien film': [\"action\",\"adventure\"],\n",
    " 'alien invasion': [\"action\"],\n",
    " 'americana': [\"drama\"],\n",
    " 'animal picture': [\"other\"],\n",
    " 'animals': [\"other\"],\n",
    " 'animated cartoon': [\"animation\"],\n",
    " 'animated musical': [\"animation\"],\n",
    " 'animation': [\"animation\"],\n",
    " 'anime': [\"animation\"],\n",
    " 'anthology': [\"genre\"],\n",
    " 'anthropology': [\"other\"],\n",
    " 'anti-war': [\"drama\"],\n",
    " 'anti-war film': [\"drama\"],\n",
    " 'apocalyptic and post-apocalyptic fiction': [\"action\",\"fantasy\"],\n",
    " 'archaeology': [\"other\"],\n",
    " 'archives and records': [\"other\"],\n",
    " 'art film': [\"genre\"],\n",
    " 'auto racing': [\"other\"],\n",
    " 'avant-garde': [\"genre\"],\n",
    " 'b-movie': [\"comedy\"],\n",
    " 'b-western': [\"action\",\"comedy\"],\n",
    " 'backstage musical': [\"other\"],\n",
    " 'baseball': [\"other\"],\n",
    " 'beach film': [\"other\"],\n",
    " 'beach party film': [\"comedy\"],\n",
    " 'bengali cinema': [\"other\"],\n",
    " 'biker film':[\"action\"],\n",
    " 'biographical film': [\"other\"],\n",
    " 'biography': [\"other\"],\n",
    " 'biopic [feature]': [\"other\"],\n",
    " 'black comedy': [\"comedy\"],\n",
    " 'black-and-white': [\"other\"],\n",
    " 'blaxploitation':[\"drama\"],\n",
    " 'bloopers & candid camera': [\"comedy\"],\n",
    " 'bollywood': [\"other\"],\n",
    " 'boxing': [\"other\"],\n",
    " 'breakdance': [\"other\"],\n",
    " 'british empire film': [\"other\"],\n",
    " 'british new wave': [\"genre\"],\n",
    " 'bruceploitation':[\"action\"],\n",
    " 'buddy cop': [\"action\",\"comedy\"],\n",
    " 'buddy film': [\"comedy\"],\n",
    " 'buddy picture': [\"comedy\"],\n",
    " 'business': [\"other\"],\n",
    " 'camp': [\"other\"],\n",
    " 'caper story': [\"thriller\"],\n",
    " 'cavalry film': [\"action\"],\n",
    " 'chase movie': [\"thriller\"],\n",
    " 'childhood drama': [\"drama\"],\n",
    " \"children's\": [\"family\"],\n",
    " \"children's entertainment\": [\"family\"],\n",
    " \"children's fantasy\": [\"family\",\"fantasy\"],\n",
    " \"children's issues\": [\"drama\"],\n",
    " \"children's/family\": [\"family\"],\n",
    " 'chinese movies': [\"other\"],\n",
    " 'christian film': [\"other\"],\n",
    " 'christmas movie': [\"other\"],\n",
    " 'clay animation': [\"animation\"],\n",
    " 'cold war': [\"adventure\",\"action\"],\n",
    " 'combat films': [\"action\"],\n",
    " 'comdedy': [\"comedy\"],\n",
    " 'comedy': [\"comedy\"],\n",
    " 'comedy film': [\"comedy\"],\n",
    " 'comedy horror': [\"horror\",\"comedy\"],\n",
    " 'comedy of errors': [\"comedy\"],\n",
    " 'comedy of manners': [\"comedy\"],\n",
    " 'comedy thriller': [\"thriller\",\"comedy\"],\n",
    " 'comedy western': [\"action\",\"comedy\"],\n",
    " 'comedy-drama': [\"drama\",\"comedy\"],\n",
    " 'coming of age': [\"comedy\"],\n",
    " 'coming-of-age film': [\"comedy\"],\n",
    " 'computer animation': [\"animation\"],\n",
    " 'computers': [\"animation\"],\n",
    " 'concert film': [\"other\"],\n",
    " 'conspiracy fiction': [\"thriller\"],\n",
    " 'costume adventure': [\"adventure\"],\n",
    " 'costume drama': [\"drama\"],\n",
    " 'costume horror': [\"horror\"],\n",
    " 'courtroom comedy': [\"comedy\"],\n",
    " 'courtroom drama': [\"drama\"],\n",
    " 'creature film': [\"adventure\",\"fantasy\"],\n",
    " 'crime': [\"thriller\"],\n",
    " 'crime comedy': [\"thriller\",\"comedy\"],\n",
    " 'crime drama': [\"thriller\",\"drama\"],\n",
    " 'crime fiction': [\"thriller\"],\n",
    " 'crime thriller': [\"thriller\"],\n",
    " 'cult': [\"other\"],\n",
    " 'culture & society': [\"other\"],\n",
    " 'cyberpunk': [\"fantasy\"],\n",
    " 'czechoslovak new wave': [\"genre\"],\n",
    " 'dance': [\"other\"],\n",
    " 'demonic child': [\"horror\"],\n",
    " 'detective': [\"thriller\"],\n",
    " 'detective fiction': [\"thriller\"],\n",
    " 'disaster': [\"drama\"],\n",
    " 'docudrama': [\"drama\"],\n",
    " 'documentary': [\"other\"],\n",
    " 'dogme 95': [\"genre\"],\n",
    " 'domestic comedy': [\"comedy\"],\n",
    " 'doomsday film': [\"fantasy\"],\n",
    " 'drama': [\"drama\"],\n",
    " 'dystopia': [\"drama\",\"fantasy\"],\n",
    " 'ealing comedies': [\"comedy\"],\n",
    " 'early black cinema': [\"other\"],\n",
    " 'education': [\"family\"],\n",
    " 'educational': [\"family\"],\n",
    " 'ensemble film': [\"genre\"],\n",
    " 'environmental science': [\"other\"],\n",
    " 'epic': [\"adventure\"],\n",
    " 'epic western': [\"adventure\",\"action\"],\n",
    " 'erotic drama': [\"adult\",\"drama\"],\n",
    " 'erotic thriller': [\"thriller\",\"adult\"],\n",
    " 'erotica': [\"adult\"],\n",
    " 'escape film': [\"thriller\"],\n",
    " 'essay film': [\"genre\"],\n",
    " 'existentialism': [\"genre\"],\n",
    " 'experimental film': [\"genre\"],\n",
    " 'exploitation': [\"drama\"],\n",
    " 'expressionism': [\"genre\"],\n",
    " 'extreme sports': [\"other\"],\n",
    " 'fairy tale': [\"fantasy\",\"adventure\"],\n",
    " 'family & personal relationships': [\"drama\"],\n",
    " 'family drama': [\"drama\"],\n",
    " 'family film': [\"family\"],\n",
    " 'family-oriented adventure': [\"family\",\"adventure\"],\n",
    " 'fan film': [\"other\"],\n",
    " 'fantasy': [\"fantasy\"],\n",
    " 'fantasy adventure': [\"fantasy\",\"adventure\"],\n",
    " 'fantasy comedy': [\"fantasy\",\"comedy\"],\n",
    " 'fantasy drama': [\"fantasy\",\"drama\"],\n",
    " 'feature film': [\"other\"],\n",
    " 'female buddy film': [\"comedy\"],\n",
    " 'feminist film': [\"drama\"],\n",
    " 'fictional film': [\"other\"],\n",
    " 'filipino': [\"other\"],\n",
    " 'filipino movies': [\"other\"],\n",
    " 'film': [\"other\"],\n",
    " 'film & television history': [\"other\"],\n",
    " 'film adaptation': [\"other\"],\n",
    " 'film noir': [\"thriller\"],\n",
    " 'film Ã  clef': [\"drama\"],\n",
    " 'film-opera': [\"other\"],\n",
    " 'filmed play': [\"other\"],\n",
    " 'finance & investing': [\"other\"],\n",
    " 'foreign legion':[\"action\"],\n",
    " 'future noir': [\"fantasy\",\"drama\"],\n",
    " 'gangster film': [\"thriller\",\"action\"],\n",
    " 'gay': [\"drama\"],\n",
    " 'gay interest': [\"drama\"],\n",
    " 'gay pornography': [\"adult\"],\n",
    " 'gay themed': [\"drama\"],\n",
    " 'gender issues': [\"drama\"],\n",
    " 'giallo': [\"thriller\"],\n",
    " 'glamorized spy film': [\"thriller\"],\n",
    " 'goat gland': [\"genre\"],\n",
    " 'gothic film': [\"genre\"],\n",
    " 'graphic & applied arts': [\"genre\"],\n",
    " 'gross out': [\"comedy\"],\n",
    " 'gross-out film': [\"comedy\"],\n",
    " 'gulf war':[\"action\"],\n",
    " 'hagiography': [\"other\"],\n",
    " 'hardcore pornography': [\"adult\"],\n",
    " 'haunted house film': [\"horror\"],\n",
    " 'health & fitness': [\"other\"],\n",
    " 'heaven-can-wait fantasies': [\"fantasy\"],\n",
    " 'heavenly comedy': [\"comedy\"],\n",
    " 'heist': [\"action\"],\n",
    " 'hip hop movies': [\"other\"],\n",
    " 'historical documentaries': [\"other\"],\n",
    " 'historical drama': [\"drama\"],\n",
    " 'historical epic': [\"adventure\"],\n",
    " 'historical fiction': [\"other\"],\n",
    " 'history': [\"other\"],\n",
    " 'holiday film': [\"comedy\"],\n",
    " 'horror': [\"horror\"],\n",
    " 'horror comedy': [\"horror\",\"comedy\"],\n",
    " 'horse racing': [\"other\"],\n",
    " 'humour': [\"comedy\"],\n",
    " 'hybrid western': [\"adventure\",\"action\"],\n",
    " 'illnesses & disabilities': [\"drama\"],\n",
    " 'indian western': [\"adventure\",\"action\"],\n",
    " 'indie': [\"genre\"],\n",
    " 'inspirational drama': [\"drama\"],\n",
    " 'instrumental music': [\"other\"],\n",
    " 'interpersonal relationships': [\"drama\"],\n",
    " 'inventions & innovations': [\"other\"],\n",
    " 'japanese movies': [\"other\"],\n",
    " 'journalism': [\"other\"],\n",
    " 'jukebox musical': [\"other\"],\n",
    " 'jungle film': [\"adventure\"],\n",
    " 'juvenile delinquency film': [\"drama\"],\n",
    " 'kafkaesque': [\"genre\"],\n",
    " 'kitchen sink realism': [\"genre\"],\n",
    " 'language & literature': [\"genre\"],\n",
    " 'latino': [\"other\"],\n",
    " 'law & crime': [\"thriller\"],\n",
    " 'legal drama': [\"drama\"],\n",
    " 'lgbt': [\"drama\"],\n",
    " 'libraries and librarians': [\"other\"],\n",
    " 'live action': [\"other\"],\n",
    " 'malayalam cinema': [\"other\"],\n",
    " 'marriage drama': [\"drama\"],\n",
    " 'martial arts film': [\"action\"],\n",
    " 'master criminal films': [\"thriller\"],\n",
    " 'media satire': [\"other\"],\n",
    " 'media studies': [\"other\"],\n",
    " 'medical fiction': [\"other\"],\n",
    " 'melodrama': [\"drama\"],\n",
    " 'mockumentary': [\"other\"],\n",
    " 'mondo film': [\"genre\"],\n",
    " 'monster': [\"horror\",\"action\"],\n",
    " 'monster movie': [\"horror\",\"action\"],\n",
    " 'movie serial': [\"other\"],\n",
    " 'movies about gladiators': [\"other\"],\n",
    " 'mumblecore': [\"genre\"],\n",
    " 'music': [\"other\"],\n",
    " 'musical': [\"other\"],\n",
    " 'musical comedy': [\"comedy\"],\n",
    " 'musical drama': [\"drama\"],\n",
    " 'mystery': [\"thriller\"],\n",
    " 'mythological fantasy': [\"fantasy\"],\n",
    " 'natural disaster': [\"other\"],\n",
    " 'natural horror films': [\"horror\"],\n",
    " 'nature': [\"other\"],\n",
    " 'neo-noir': [\"thriller\"],\n",
    " 'neorealism': [\"genre\"],\n",
    " 'new hollywood': [\"genre\"],\n",
    " 'new queer cinema': [\"drama\"],\n",
    " 'news': [\"other\"],\n",
    " 'ninja movie': [\"action\"],\n",
    " 'northern': [\"genre\"],\n",
    " 'operetta': [\"other\"],\n",
    " 'outlaw': [\"other\"],\n",
    " 'outlaw biker film': [\"other\"],\n",
    " 'parkour in popular culture': [\"action\"],\n",
    " 'parody': [\"comedy\"],\n",
    " 'patriotic film': [\"other\"],\n",
    " 'period horror': [\"horror\"],\n",
    " 'period piece': [\"drama\"],\n",
    " 'pinku eiga': [\"adult\"],\n",
    " 'plague': [\"drama\"],\n",
    " 'point of view shot': [\"other\"],\n",
    " 'political cinema': [\"other\"],\n",
    " 'political documetary': [\"other\"],\n",
    " 'political drama': [\"drama\"],\n",
    " 'political satire': [\"drama\"],\n",
    " 'political thriller': [\"thriller\"],\n",
    " 'pornographic movie': [\"adult\"],\n",
    " 'pornography': [\"adult\"],\n",
    " 'pre-code': [\"other\"],\n",
    " 'prison': [\"action\"],\n",
    " 'prison escape': [\"action\"],\n",
    " 'prison film': [\"action\"],\n",
    " 'private military company': [\"action\"],\n",
    " 'propaganda film': [\"other\"],\n",
    " 'psycho-biddy': [\"horror\",\"thriller\"],\n",
    " 'psychological horror': [\"horror\"],\n",
    " 'psychological thriller': [\"thriller\"],\n",
    " 'punk rock': [\"genre\"],\n",
    " 'race movie': [\"action\"],\n",
    " 'reboot': [\"other\"],\n",
    " 'religious film': [\"other\"],\n",
    " 'remake': [\"other\"],\n",
    " 'revenge': [\"action\"],\n",
    " 'revisionist fairy tale': [\"adventure\",\"fantasy\"],\n",
    " 'revisionist western': [\"adventure\",\"action\"],\n",
    " 'road movie': [\"other\"],\n",
    " 'road-horror': [\"horror\"],\n",
    " 'roadshow theatrical release': [\"other\"],\n",
    " 'roadshow/carny': [\"other\"],\n",
    " 'rockumentary': [\"other\"],\n",
    " 'romance film': [\"other\"],\n",
    " 'romantic comedy': [\"comedy\"],\n",
    " 'romantic drama': [\"drama\"],\n",
    " 'romantic fantasy': [\"fantasy\"],\n",
    " 'romantic thriller': [\"thriller\"],\n",
    " 'samurai cinema': [\"adventure\",\"action\"],\n",
    " 'satire': [\"comedy\"],\n",
    " 'school story': [\"family\"],\n",
    " 'sci-fi adventure': [\"fantasy\",\"adventure\"],\n",
    " 'sci-fi horror': [\"fantasy\",\"horror\"],\n",
    " 'sci-fi thriller': [\"fantasy\",\"thriller\"],\n",
    " 'science fiction': [\"fantasy\"],\n",
    " 'science fiction western': [\"adventure\",\"fantasy\",\"action\"],\n",
    " 'screwball comedy': [\"comedy\"],\n",
    " 'sex comedy': [\"comedy\"],\n",
    " 'sexploitation': [\"drama\"],\n",
    " 'short film': [\"other\"],\n",
    " 'silent film': [\"other\"],\n",
    " 'singing cowboy': [\"action\",\"adventure\"],\n",
    " 'slapstick': [\"comedy\"],\n",
    " 'slasher': [\"horror\",\"action\"],\n",
    " 'slice of life story': [\"drama\"],\n",
    " 'social issues': [\"drama\"],\n",
    " 'social problem film': [\"drama\"],\n",
    " 'softcore porn': [\"adult\"],\n",
    " 'space opera': [\"fantasy\",\"adventure\"],\n",
    " 'space western': [\"adventure\",\"action\"],\n",
    " 'spaghetti western': [\"adventure\",\"action\"],\n",
    " 'splatter film': [\"horror\"],\n",
    " 'sports': [\"other\"],\n",
    " 'spy': [\"thriller\"],\n",
    " 'stand-up comedy': [\"comedy\"],\n",
    " 'star vehicle': [\"other\"],\n",
    " 'steampunk': [\"fantasy\"],\n",
    " 'stoner film': [\"genre\"],\n",
    " 'stop motion': [\"animation\"],\n",
    " 'superhero': [\"action\"],\n",
    " 'superhero movie': [\"action\"],\n",
    " 'supermarionation': [\"animation\"],\n",
    " 'supernatural': [\"fantasy\"],\n",
    " 'surrealism': [\"genre\"],\n",
    " 'suspense': [\"thriller\"],\n",
    " 'swashbuckler films': [\"action\",\"adventure\"],\n",
    " 'sword and sandal': [\"adventure\"],\n",
    " 'sword and sorcery': [\"fantasy\",\"adventure\"],\n",
    " 'sword and sorcery films': [\"fantasy\",\"adventure\"],\n",
    " 'tamil cinema': [\"other\"],\n",
    " 'teen': [\"family\"],\n",
    " 'television movie': [\"other\"],\n",
    " 'the netherlands in world war ii': [\"action\"],\n",
    " 'therimin music': [\"other\"],\n",
    " 'thriller': [\"thriller\"],\n",
    " 'time travel': [\"adventure\"],\n",
    " 'tokusatsu': [\"other\"],\n",
    " 'tollywood': [\"other\"],\n",
    " 'tragedy': [\"drama\"],\n",
    " 'tragicomedy': [\"comedy\"],\n",
    " 'travel': [\"adventure\"],\n",
    " 'vampire movies': [\"horror\",\"action\"],\n",
    " 'war effort': [\"action\"],\n",
    " 'war film': [\"action\"],\n",
    " 'werewolf fiction': [\"horror\"],\n",
    " 'western': [\"adventure\",\"action\"],\n",
    " 'whodunit': [\"thriller\"],\n",
    " 'women in prison films': [\"drama\"],\n",
    " 'workplace comedy': [\"comedy\"],\n",
    " 'world cinema': [\"other\"],\n",
    " 'world history': [\"other\"],\n",
    " 'wuxia': [\"adventure\"],\n",
    " 'z movie': [\"horror\"],\n",
    " 'zombie film': [\"horror\"]}\n",
    "\n",
    "GENRE_ENCODING = {\n",
    "    \"action\":    [1,0,0,0,0,0,0,0,0,0,0],\n",
    "    \"adventure\": [0,1,0,0,0,0,0,0,0,0,0],\n",
    "    \"comedy\":    [0,0,1,0,0,0,0,0,0,0,0],\n",
    "    \"drama\":     [0,0,0,1,0,0,0,0,0,0,0],\n",
    "    \"thriller\":  [0,0,0,0,1,0,0,0,0,0,0],\n",
    "    \"horror\":    [0,0,0,0,0,1,0,0,0,0,0],\n",
    "    \"animation\": [0,0,0,0,0,0,1,0,0,0,0],\n",
    "    \"family\":    [0,0,0,0,0,0,0,1,0,0,0],\n",
    "    \"adult\":     [0,0,0,0,0,0,0,0,1,0,0],\n",
    "    \"fantasy\":   [0,0,0,0,0,0,0,0,0,1,0],\n",
    "    \"genre\":     [0,0,0,0,0,0,0,0,0,0,1],\n",
    "    \"other\":     [0,0,0,0,0,0,0,0,0,0,0]\n",
    "}\n",
    "\n",
    "GENRE_LIST = [\"action\",\"adventure\",\"comedy\",\"drama\",\"thriller\",\"horror\",\n",
    "                   \"animation\",\"children\",\"adult\",\"fantasy\",\"genre\"]\n",
    "\n",
    "DEFAULT_PARAMETERS = {\"drop\": [\"name\",\"revenue\",\"has_common_character_name\",\"character_number\"],\n",
    "              \"nan_filtering\":[\"all\"],\n",
    "              \"decades\":[],\n",
    "              \"log\":[],\n",
    "              \"standardize\":[\"title_length\"]}\n",
    "\n",
    "SUCCESS_THRESHOLD = 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2aae8",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33e62d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_pickle(\"../../data/post_processing//country_df.pkl\")\n",
    "comes_from_df = pd.read_pickle(\"../../data/post_processing/comes_from_df.pkl\")\n",
    "genre_df = pd.read_pickle(\"../../data/post_processing/genre_df.pkl\")\n",
    "is_of_type_df = pd.read_pickle(\"../../data/post_processing/is_of_type_df.pkl\")\n",
    "language_df = pd.read_pickle(\"../../data/post_processing/language_df.pkl\")\n",
    "spoken_languages_df = pd.read_pickle(\"../../data/post_processing/spoken_languages_df.pkl\")\n",
    "character_df = pd.read_pickle(\"../../data/post_processing/character_df.pkl\")\n",
    "actor_df = pd.read_pickle(\"../../data/post_processing/actor_df.pkl\")\n",
    "movie_df = pd.read_pickle(\"../../data/post_processing/movie_df.pkl\")\n",
    "belongs_to_df = pd.read_pickle(\"../../data/post_processing/belongs_to_df.pkl\")\n",
    "play_df = pd.read_pickle(\"../../data/post_processing/play_df.pkl\")\n",
    "appears_in_df = pd.read_pickle(\"../../data/post_processing/appears_in_df.pkl\")\n",
    "wikipedia_imdb_mapping_table = pd.read_pickle(\"../../data/generated/wikipedia_imdb_mapping_df.pkl\")\n",
    "is_directed_by_df = pd.read_pickle(\"../../data/post_processing/is_directed_by_df.pkl\")\n",
    "director_df = pd.read_pickle(\"../../data/post_processing/director_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5f828",
   "metadata": {},
   "source": [
    "## Create Regression DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7799a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df = movie_df.copy()\n",
    "movie_regression_df.drop([\"freebase_id\",\"plot\"],axis=1,inplace=True)\n",
    "movie_regression_df[\"num_votes\"] = movie_regression_df[\"num_votes\"].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4850587",
   "metadata": {},
   "source": [
    "## Countries\n",
    "\n",
    "For the countries we can already try to group per continent. It will give an idea of the different local influence without going in too much details. We suggest the following partition based on our previous analyses:\n",
    "\n",
    "- North America and Australia\n",
    "- Central and South America\n",
    "- Western Europe\n",
    "- Eastern Europe and Russia\n",
    "- Africa and Middle-East\n",
    "- Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410da0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_movie_df = comes_from_df.copy()\n",
    "country_movie_df[\"country_encoding\"] = country_movie_df[\"country_name\"].apply(\n",
    "    lambda c: COUNTRY_CONTINENT_MAPPING[c])\n",
    "country_movie_df[\"country_encoding\"] = country_movie_df[\"country_encoding\"].apply(\n",
    "    lambda c: np.array(COUNTRY_ENCODING[c]))\n",
    "for continent in CONTINENT_LIST:\n",
    "    country_movie_df[continent] = country_movie_df[\"country_encoding\"].apply(\n",
    "        lambda l: l[CONTINENT_LIST.index(continent)])\n",
    "    movie_regression_df[continent] = country_movie_df.groupby(\"movie_id\")[continent].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1b3cb",
   "metadata": {},
   "source": [
    "## Actors\n",
    "\n",
    "For the actors, we thought about the following features:\n",
    "- #number of actors in the top 5% (or 1% ?)\n",
    "- #number of actors\n",
    "- mean actor age\n",
    "- gender balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07189e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1014 actors in the top 99%.\n"
     ]
    }
   ],
   "source": [
    "percentile = 99\n",
    "actor_movie_count = appears_in_df.groupby(\"actor_id\")[\"movie_id\"].count().values\n",
    "threshold = np.percentile(actor_movie_count,percentile)\n",
    "is_actor_above_threshold = appears_in_df.groupby(\"actor_id\")[\"movie_id\"].count().sort_index() >= threshold\n",
    "top_k_actors = actor_df[is_actor_above_threshold.values]\n",
    "print(f\"There are {len(top_k_actors)} actors in the top {percentile}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650f0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_movie_df = appears_in_df.merge(actor_df[\"gender\"],how=\"left\",on=\"actor_id\")\n",
    "actor_movie_df[\"gender\"] = actor_movie_df[\"gender\"].apply(\n",
    "    lambda g: -1 if g == \"M\" else 1 if g == \"F\" else g)\n",
    "actor_movie_df[\"is_top_k\"] = actor_movie_df[\"actor_id\"].isin(set(top_k_actors.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663baac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"actor_number\"] = actor_movie_df.groupby(\"movie_id\")[\"actor_id\"].count()\n",
    "movie_regression_df[\"mean_actor_age\"] = actor_movie_df.groupby(\"movie_id\")[\"actor_age\"].mean()\n",
    "movie_regression_df[\"gender_ratio\"] = actor_movie_df.groupby(\"movie_id\")[\"gender\"].mean()\n",
    "movie_regression_df[\"has_famous_actor\"] = actor_movie_df.groupby(\"movie_id\")[\"is_top_k\"].max()\n",
    "movie_regression_df[\"has_famous_actor\"] = movie_regression_df[\"has_famous_actor\"].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d448350",
   "metadata": {},
   "source": [
    "## Genre\n",
    "\n",
    "For the genre we suggest the following features:\n",
    "- #genres\n",
    "- One-hot-encoding of genre cluster:\n",
    "    - action\n",
    "    - adventure\n",
    "    - comedy\n",
    "    - drame\n",
    "    - thriller\n",
    "    - horror\n",
    "    - animation\n",
    "    - children\n",
    "    - adult\n",
    "    - fantasy\n",
    "    - genre\n",
    "    - other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9cd528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_movie_df = is_of_type_df.copy()\n",
    "genre_movie_df[\"genre_encoding\"] = genre_movie_df[\"genre_name\"].apply(lambda g: GENRE_MAPPING[g])\n",
    "genre_movie_df[\"genre_encoding\"] = genre_movie_df[\"genre_encoding\"].apply(\n",
    "    lambda l: np.sum([np.array(GENRE_ENCODING[g]) for g in l],axis=0))\n",
    "for genre in GENRE_LIST:\n",
    "    genre_movie_df[genre] = genre_movie_df[\"genre_encoding\"].apply(\n",
    "        lambda l: l[GENRE_LIST.index(genre)])\n",
    "    movie_regression_df[genre] = genre_movie_df.groupby(\"movie_id\")[genre].max()\n",
    "movie_regression_df[\"genre_number\"] = genre_movie_df.groupby(\"movie_id\")[\"genre_name\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc1dd0",
   "metadata": {},
   "source": [
    "## Languages\n",
    "\n",
    "For the languages we suggest the following features:\n",
    "- #languages\n",
    "- top languages\n",
    "- total population covered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a7b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_language = 5\n",
    "language_movie_df = spoken_languages_df.copy()\n",
    "top_k_languages = set(language_movie_df.groupby(\"language_name\")[\"movie_id\"].count().sort_values(\n",
    "    ascending=False).head(k_language).index)\n",
    "language_movie_df[\"top_language\"] = language_movie_df[\"language_name\"].isin(top_k_languages)\n",
    "movie_regression_df[\"has_common_language\"] = language_movie_df.groupby(\"movie_id\")[\"top_language\"].max()\n",
    "movie_regression_df[\"has_common_language\"] = movie_regression_df[\"has_common_language\"].replace({True: 1, False: 0})\n",
    "movie_regression_df[\"language_number\"] = language_movie_df.groupby(\"movie_id\")[\"language_name\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0310531",
   "metadata": {},
   "source": [
    "## Characters\n",
    "- #characters\n",
    "- usage of common names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0dc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_characters = 20\n",
    "top_k_characters_names = set(character_df[\"character_name\"].value_counts().head(k_characters).index)\n",
    "top_k_characters_ids = set(character_df[character_df[\"character_name\"].isin(top_k_characters_names)].index)\n",
    "character_movie_df = belongs_to_df.copy()\n",
    "character_movie_df[\"common_character_name\"] = character_movie_df[\"character_id\"].isin(top_k_characters_ids)\n",
    "movie_regression_df[\"has_common_character_name\"] = character_movie_df.groupby(\n",
    "    \"movie_id\")[\"common_character_name\"].max()\n",
    "movie_regression_df[\"character_number\"] = character_movie_df.groupby(\n",
    "    \"movie_id\")[\"character_id\"].count()\n",
    "movie_regression_df[\"has_common_character_name\"] = movie_regression_df[\n",
    "    \"has_common_character_name\"].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e39ef",
   "metadata": {},
   "source": [
    "## Decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6505fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"decade\"] = movie_regression_df[\"release_date\"].apply(lambda d: d.year - d.year%10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996ed90",
   "metadata": {},
   "source": [
    "## Movie Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0936792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"title_length\"] = movie_regression_df[\"name\"].apply(lambda n: len(n.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5733b",
   "metadata": {},
   "source": [
    "## Director\n",
    "\n",
    "- Has the director produced a successful movie in the past decades\n",
    "- Has the director produced a successful movie in the past (coarser feature)\n",
    "- Number of movies produced by directors in the past\n",
    "\n",
    "- Number of directors on the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cdb74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def director_metrics_up_to_date(movie_dataframe: pd.DataFrame, director_movies: set, date) -> tuple:\n",
    "    \"\"\"\n",
    "    Compute the number of movies and the best ratings up to the date from the set of movies provided.\n",
    "    \n",
    "    This function allows us to have the history of performance of the set of directors that worked \n",
    "    on a given movie. You give the set of movies of the directors and the date of production of the\n",
    "    current movie and it will return the performance up to the given date.\n",
    "    \n",
    "    :param movie_dataframe: Pandas DataFrame with movie information\n",
    "    :param director_movies: Set of movies directed by the directors of the current movie.\n",
    "    :param date: Date of release of the current movie, thus the metrics are up to this date.\n",
    "    \n",
    "    :return: The number of movies and the best rating up to the given date.\n",
    "    \"\"\"\n",
    "    director_movie_df = movie_dataframe[movie_dataframe.index.isin(director_movies)]\n",
    "    movie_date_df = director_movie_df[director_movie_df[\"release_date\"] < date]\n",
    "    movie_count = len(movie_date_df)\n",
    "    if movie_count == 0:\n",
    "        return 0, None\n",
    "    best_rating = movie_date_df[\"average_rating\"].max()\n",
    "    return movie_count, best_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c641011",
   "metadata": {},
   "outputs": [],
   "source": [
    "director_movies_mapping = is_directed_by_df.groupby(\"director_id\")[\"movie_id\"].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40715261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the set of movies directed by the directors for each movie\n",
    "director_movies_df = is_directed_by_df.copy()\n",
    "director_movies_df[\"director_movies\"] = director_movies_df[\"director_id\"].apply(\n",
    "    lambda d: director_movies_mapping[d])\n",
    "director_movies_df = director_movies_df.groupby(\"movie_id\")[\"director_movies\"].apply(list)\n",
    "director_movies_df = director_movies_df.apply(\n",
    "    lambda movie_list: set([m for movie_set in movie_list for m in list(movie_set)]))\n",
    "director_movies_df = pd.DataFrame(director_movies_df)\n",
    "# Merge DataFrames to recover temporal data and rating\n",
    "new_is_directed_by_df = director_movies_df.merge(\n",
    "    movie_regression_df[[\"average_rating\",\"release_date\"]],how=\"left\",on=\"movie_id\")\n",
    "new_is_directed_by_df[\"combined_features\"] = list(zip(new_is_directed_by_df[\"director_movies\"],new_is_directed_by_df[\"release_date\"]))\n",
    "# Compute performance of the movie directing team up to the release date of each movie.\n",
    "new_is_directed_by_df[\"director_metrics\"] = new_is_directed_by_df[\"combined_features\"].apply(\n",
    "    lambda t: director_metrics_up_to_date(new_is_directed_by_df,t[0],t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc1e16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"combinned_movie_num\"] = new_is_directed_by_df[\"director_metrics\"].apply(lambda t: t[0])\n",
    "movie_regression_df[\"combinned_best_rating\"] = new_is_directed_by_df[\"director_metrics\"].apply(lambda t: t[1])\n",
    "movie_regression_df[\"num_directors\"] = is_directed_by_df.groupby(\"movie_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96fbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_regression_df[\"combinned_movie_success\"] = movie_regression_df[\"combinned_best_rating\"] > SUCCESS_THRESHOLD\n",
    "movie_regression_df[\"combinned_movie_success\"] = movie_regression_df[\n",
    "    \"combinned_movie_success\"].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18af69",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "- Preprocess plots: tokenization + casefolding + stopwords removal + lemmatization\n",
    "- BOW creation\n",
    "- BOW matrix creation\n",
    "- odds ratio computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17502715",
   "metadata": {},
   "source": [
    "### Plot Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8505885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jerem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b5510b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, an, upper, class, housewife, becomes, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171005</th>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       plot  \\\n",
       "movie_id                                                      \n",
       "975900    Set in the second half of the 22nd century, th...   \n",
       "261236    Eva, an upper class housewife, becomes frustra...   \n",
       "171005    {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...   \n",
       "\n",
       "                                                  tokenized  \n",
       "movie_id                                                     \n",
       "975900    [Set, in, the, second, half, of, the, 22nd, ce...  \n",
       "261236    [Eva, an, upper, class, housewife, becomes, fr...  \n",
       "171005    [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "movies_with_plot_df = pd.DataFrame(movie_df[~movie_df[\"plot\"].isna()][\"plot\"])\n",
    "movies_with_plot_df[\"tokenized\"] = movies_with_plot_df[\"plot\"].apply(tokenizer.tokenize)\n",
    "movies_with_plot_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f109f154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>[set, second, half, 22nd, century, film, depic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, an, upper, class, housewife, becomes, fr...</td>\n",
       "      <td>[eva, upper, class, housewife, becomes, frustr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171005</th>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...</td>\n",
       "      <td>[plot, dateact, 1act, 2act, 3act, 4act, 5, fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       plot  \\\n",
       "movie_id                                                      \n",
       "975900    Set in the second half of the 22nd century, th...   \n",
       "261236    Eva, an upper class housewife, becomes frustra...   \n",
       "171005    {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...   \n",
       "\n",
       "                                                  tokenized  \\\n",
       "movie_id                                                      \n",
       "975900    [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "261236    [Eva, an, upper, class, housewife, becomes, fr...   \n",
       "171005    [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...   \n",
       "\n",
       "                                               no_stopwords  \n",
       "movie_id                                                     \n",
       "975900    [set, second, half, 22nd, century, film, depic...  \n",
       "261236    [eva, upper, class, housewife, becomes, frustr...  \n",
       "171005    [plot, dateact, 1act, 2act, 3act, 4act, 5, fin...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords and Casefolding\n",
    "movies_with_plot_df[\"no_stopwords\"] = movies_with_plot_df[\"tokenized\"].apply(\n",
    "    lambda l: [s.casefold() for s in l if s.casefold() not in stop_words])\n",
    "movies_with_plot_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06c62a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>[set, second, half, 22nd, century, film, depic...</td>\n",
       "      <td>[set, second, half, 22nd, century, film, depic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, an, upper, class, housewife, becomes, fr...</td>\n",
       "      <td>[eva, upper, class, housewife, becomes, frustr...</td>\n",
       "      <td>[eva, upper, class, housewife, becomes, frustr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171005</th>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...</td>\n",
       "      <td>[plot, dateact, 1act, 2act, 3act, 4act, 5, fin...</td>\n",
       "      <td>[plot, dateact, 1act, 2act, 3act, 4act, 5, fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       plot  \\\n",
       "movie_id                                                      \n",
       "975900    Set in the second half of the 22nd century, th...   \n",
       "261236    Eva, an upper class housewife, becomes frustra...   \n",
       "171005    {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...   \n",
       "\n",
       "                                                  tokenized  \\\n",
       "movie_id                                                      \n",
       "975900    [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "261236    [Eva, an, upper, class, housewife, becomes, fr...   \n",
       "171005    [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...   \n",
       "\n",
       "                                               no_stopwords  \\\n",
       "movie_id                                                      \n",
       "975900    [set, second, half, 22nd, century, film, depic...   \n",
       "261236    [eva, upper, class, housewife, becomes, frustr...   \n",
       "171005    [plot, dateact, 1act, 2act, 3act, 4act, 5, fin...   \n",
       "\n",
       "                                                 lemmatized  \n",
       "movie_id                                                     \n",
       "975900    [set, second, half, 22nd, century, film, depic...  \n",
       "261236    [eva, upper, class, housewife, becomes, frustr...  \n",
       "171005    [plot, dateact, 1act, 2act, 3act, 4act, 5, fin...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize\n",
    "movies_with_plot_df[\"lemmatized\"] = movies_with_plot_df[\"no_stopwords\"].apply(\n",
    "    lambda l: [lemmatizer.lemmatize(s) for s in l])\n",
    "movies_with_plot_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a7115",
   "metadata": {},
   "source": [
    "### BOW creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "adb6e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW = set()\n",
    "for row_id, row_data in movies_with_plot_df[\"lemmatized\"].apply(lambda l: set(l)).iteritems():\n",
    "    BOW = BOW.union(row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0bb53",
   "metadata": {},
   "source": [
    "### BOW Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6e73229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BOW_mapping(words_list: list, BOW_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Map the BOW for each plot to its encoding in row id and number of occurences.\n",
    "    \n",
    "    :param words_list: List of the words contained in the plot (BOW).\n",
    "    :param BOW_dict: Dictionnary containing the mapping between words and ids in the BOW matrix.\n",
    "    \n",
    "    :return: The dictionnary with the ids of each words and their number of occurences.\n",
    "    \n",
    "    \"\"\"\n",
    "    movie_mapping = dict()\n",
    "    for w in words_list:\n",
    "        word_id = BOW_dict[w]\n",
    "        if word_id not in movie_mapping:\n",
    "            movie_mapping[word_id] = 1\n",
    "        else:\n",
    "            movie_mapping[word_id] += 1 \n",
    "    return movie_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8f63cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_dict = dict(zip(BOW,range(len(BOW))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dda5e944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>[set, second, half, 22nd, century, film, depic...</td>\n",
       "      <td>[set, second, half, 22nd, century, film, depic...</td>\n",
       "      <td>{58165: 2, 75398: 2, 4156: 1, 66141: 1, 15297:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, an, upper, class, housewife, becomes, fr...</td>\n",
       "      <td>[eva, upper, class, housewife, becomes, frustr...</td>\n",
       "      <td>[eva, upper, class, housewife, becomes, frustr...</td>\n",
       "      <td>{95024: 5, 367: 1, 67450: 1, 10939: 1, 80455: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171005</th>\n",
       "      <td>{{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...</td>\n",
       "      <td>[Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...</td>\n",
       "      <td>[plot, dateact, 1act, 2act, 3act, 4act, 5, fin...</td>\n",
       "      <td>[plot, dateact, 1act, 2act, 3act, 4act, 5, fin...</td>\n",
       "      <td>{86899: 1, 61096: 1, 14211: 1, 74318: 1, 88368...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       plot  \\\n",
       "movie_id                                                      \n",
       "975900    Set in the second half of the 22nd century, th...   \n",
       "261236    Eva, an upper class housewife, becomes frustra...   \n",
       "171005    {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...   \n",
       "\n",
       "                                                  tokenized  \\\n",
       "movie_id                                                      \n",
       "975900    [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "261236    [Eva, an, upper, class, housewife, becomes, fr...   \n",
       "171005    [Plot, dateAct, 1Act, 2Act, 3Act, 4Act, 5, Fin...   \n",
       "\n",
       "                                               no_stopwords  \\\n",
       "movie_id                                                      \n",
       "975900    [set, second, half, 22nd, century, film, depic...   \n",
       "261236    [eva, upper, class, housewife, becomes, frustr...   \n",
       "171005    [plot, dateact, 1act, 2act, 3act, 4act, 5, fin...   \n",
       "\n",
       "                                                 lemmatized  \\\n",
       "movie_id                                                      \n",
       "975900    [set, second, half, 22nd, century, film, depic...   \n",
       "261236    [eva, upper, class, housewife, becomes, frustr...   \n",
       "171005    [plot, dateact, 1act, 2act, 3act, 4act, 5, fin...   \n",
       "\n",
       "                                                   encoding  \n",
       "movie_id                                                     \n",
       "975900    {58165: 2, 75398: 2, 4156: 1, 66141: 1, 15297:...  \n",
       "261236    {95024: 5, 367: 1, 67450: 1, 10939: 1, 80455: ...  \n",
       "171005    {86899: 1, 61096: 1, 14211: 1, 74318: 1, 88368...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_plot_df[\"encoding\"] = movies_with_plot_df[\"lemmatized\"].apply(\n",
    "    lambda l: BOW_mapping(l,BOW_dict))\n",
    "movies_with_plot_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "57e67b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_ids = list(range(len(movies_with_plot_df)))\n",
    "row_ids = movies_with_plot_df[\"encoding\"].apply(lambda d: list(d.keys()))\n",
    "data = movies_with_plot_df[\"encoding\"].apply(lambda d: list(d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791074bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eaad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([[1,2,3],[1,2],[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "25231e5a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\scipy\\sparse\\base.py:322\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\scipy\\sparse\\coo.py:404\u001b[0m, in \u001b[0;36mcoo_matrix.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    403\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(col, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 404\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mupcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m coo_tocsr(M, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, row, col, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    407\u001b[0m           indptr, indices, data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\scipy\\sparse\\sputils.py:51\u001b[0m, in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno supported conversion for types: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (args,))\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [140], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m csr_matrix(data, (column_ids,row_ids))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\scipy\\sparse\\compressed.py:86\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_matrix constructor usage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coo_matrix\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_self(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcoo_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Read matrix dimensions given, if any\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\scipy\\sparse\\compressed.py:34\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     32\u001b[0m         arg1 \u001b[38;5;241m=\u001b[39m arg1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m         arg1 \u001b[38;5;241m=\u001b[39m \u001b[43marg1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_self(arg1)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg1, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\scipy\\sparse\\base.py:324\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_method(copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m--> 324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\scipy\\sparse\\coo.py:404\u001b[0m, in \u001b[0;36mcoo_matrix.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    402\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(M \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[0;32m    403\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(col, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 404\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mupcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m coo_tocsr(M, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, row, col, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    407\u001b[0m           indptr, indices, data)\n\u001b[0;32m    409\u001b[0m x \u001b[38;5;241m=\u001b[39m csr_matrix((data, indices, indptr), shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\scipy\\sparse\\sputils.py:51\u001b[0m, in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     48\u001b[0m         _upcast_memo[\u001b[38;5;28mhash\u001b[39m(args)] \u001b[38;5;241m=\u001b[39m t\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno supported conversion for types: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (args,))\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "csr_matrix(data, (column_ids,row_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f2491",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fba07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column(dataframe: pd.DataFrame, col_name: str):\n",
    "    \"\"\"\n",
    "    Standardize the given column in the provided dataframe.\n",
    "    \n",
    "    :param dataframe: Pandas DataFrame containing the data.\n",
    "    :param col_name: Name of the column to standardize.\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe[col_name] = (dataframe[col_name]-\n",
    "        dataframe[col_name].mean())/dataframe[col_name].std()\n",
    "    \n",
    "def process_dataframe(dataframe: pd.DataFrame,\n",
    "                      parameters={\"drop\": [], \"nan_filtering\":[\"all\"],\"decades\":[],\n",
    "                                  \"log\":[], \"standardize\":[]}) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pre-process the dataframe for regression given the instructions in parameters.\n",
    "    \n",
    "    :param dataframe: Pandas DataFrame with the movie data for regression\n",
    "    :param parameters: Dictionnary with the different parameters for pre-processing:\n",
    "                            - drop: List of columns to drop.\n",
    "                            - nan_filtering: List of columns where nan rows should be excluded.\n",
    "                            - decades: List of decades to keep. If empty, keep all decades.\n",
    "                            - log: List of columns to log transform.\n",
    "                            - standardize: List of columns to standardize.\n",
    "                    \n",
    "    \n",
    "    :return: Processed Pandas DataFrame ready for regression.\n",
    "    \n",
    "    \"\"\"\n",
    "    regression_df = dataframe.copy()\n",
    "    # Filter out columns\n",
    "    regression_df = regression_df.drop(parameters[\"drop\"],axis=1)\n",
    "    # Filter out decades\n",
    "    if len(parameters[\"decades\"]) != 0:\n",
    "        regression_df = regression_df[\n",
    "            regression_df[\"decade\"].isin(parameters[\"decades\"])]\n",
    "    # Filter out NaN\n",
    "    if len(parameters[\"nan_filtering\"]) != 0:\n",
    "        if parameters[\"nan_filtering\"][0] == \"all\":\n",
    "            regression_df = regression_df.dropna(how=\"any\")\n",
    "        else:\n",
    "            regression_df = regression_df.dropna(subset=parameters[\"nan_filtering\"])\n",
    "    # Transform\n",
    "    for col in parameters[\"log\"]:\n",
    "        regression_df[\"log_\"+col] = regression_df[col].apply(np.log)\n",
    "    # Standardize\n",
    "    for col in parameters[\"standardize\"]:\n",
    "        standardize_column(regression_df,col)\n",
    "    return regression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23888ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_feature(regression_df: pd.DataFrame, target: pd.Series,\n",
    "                        current_features=[], ignored_features=[], \n",
    "                        alpha=0.05, show=False) -> str:\n",
    "    \"\"\"\n",
    "    Report the best feature to integrate to the current OLS model based on r-squared.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    :param target: Pandas Series representing the target values.\n",
    "    :param current_features: List of features integrated in the actual model.\n",
    "    :param ignored_features: List of features that should not be integrated in the regression.\n",
    "    :param alpha: Significance level, default 0.05.\n",
    "    :param show: Display the different features scores.\n",
    "    \n",
    "    :result: Name of the best feature or None if no new significant features.\n",
    "    \n",
    "    \"\"\"\n",
    "    result_dict = {'predictor': [], 'r-squared':[], \"aic\":[], \"p_value\":[]}\n",
    "    for col in regression_df.columns:\n",
    "        if col not in (current_features+ignored_features):\n",
    "            X = regression_df[current_features + [col]]\n",
    "            model = sm.OLS(target, sm.add_constant(X)).fit()\n",
    "            #Add the column name to our dictionary\n",
    "            result_dict['predictor'].append(col)\n",
    "            #Calculate the r-squared value between the target and predicted target\n",
    "            r2 = model.rsquared\n",
    "            #Add the model metrics to our dictionary\n",
    "            result_dict['r-squared'].append(r2)\n",
    "            result_dict['aic'].append(model.aic)\n",
    "            result_dict['p_value'].append(model.pvalues.loc[col])\n",
    "    #Once it's iterated through every column, turn our dict into a sorted DataFrame\n",
    "    candidates_features = pd.DataFrame(result_dict).sort_values(by=['r-squared'],\n",
    "                                                          ascending = False)\n",
    "    if show:\n",
    "        display(candidates_features.head())\n",
    "        \n",
    "    candidates_features = candidates_features[candidates_features[\"p_value\"] < alpha]\n",
    "    if len(candidates_features) == 0:\n",
    "        return \"None\"\n",
    "    else:\n",
    "        return candidates_features[\"predictor\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a962f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(regression_df: pd.DataFrame, target: pd.Series,\n",
    "                        ignored_features=[], alpha=0.05, show=False) -> list:\n",
    "    \"\"\"\n",
    "    Iterative forward feature selection based on r-squared without interaction terms.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    :param target: Pandas Series representing the target values.\n",
    "    :param current_features: List of features integrated in the actual model.\n",
    "    :param ignored_features: List of features that should not be integrated in the regression.\n",
    "    :param alpha: Significance level, default 0.05.\n",
    "    :param show: Display the different features scores.\n",
    "    \n",
    "    :result: List of the best features to model the target.\n",
    "    \n",
    "    \"\"\"\n",
    "    last_feature = \"\"\n",
    "    current_features = []\n",
    "    while ((len(ignored_features) + len(current_features)) < len(regression_df)\n",
    "           and last_feature != \"None\"):\n",
    "        last_feature = select_next_feature(regression_df, target,\n",
    "                        current_features=current_features,\n",
    "                        ignored_features=ignored_features, \n",
    "                        alpha=alpha, show=show)\n",
    "        if last_feature != \"None\":\n",
    "            current_features.append(last_feature)\n",
    "    return current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "328d8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_VIF_dataframe(regression_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the VIF for each features in the given dataframe.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    \n",
    "    :return: Pandas DataFrame with the VIF for each features.\n",
    "    \n",
    "    \"\"\"\n",
    "    vif_features = regression_df.columns\n",
    "    vif_values = [variance_inflation_factor(regression_df.values, i) \n",
    "                for i in range(len(regression_df.columns))]\n",
    "    vif_df = pd.DataFrame(np.array([vif_features,vif_values]).T,columns=[\"predictor\",\"VIF\"])\n",
    "    return vif_df\n",
    "\n",
    "def filter_multicolinearity(regression_df: pd.DataFrame, threshold=5):\n",
    "    \"\"\"\n",
    "    Remove the features that shows high multicollinearity based on VIF.\n",
    "    \n",
    "    :param regression_df: Pandas DataFrame containing the data for regression.\n",
    "    :param threshold: Threshold above which a VIF is considered to high to be kept. \n",
    "    \n",
    "    :return: Pandas DataFrame with data for regression without high multicollinearity.\n",
    "    \n",
    "    \"\"\"\n",
    "    new_regression_df = regression_df.copy()\n",
    "    vif_df = create_VIF_dataframe(new_regression_df)\n",
    "    high_VIF = (vif_df[\"VIF\"] > threshold).sum()\n",
    "    while high_VIF:\n",
    "        highest_VIF_predictor = vif_df.iloc[\n",
    "            vif_df[\"VIF\"].astype(np.float32).argmax()][\"predictor\"]\n",
    "        new_regression_df = new_regression_df.drop(highest_VIF_predictor,axis=1)\n",
    "        vif_df = create_VIF_dataframe(new_regression_df)\n",
    "        high_VIF = (vif_df[\"VIF\"] > threshold).sum()\n",
    "    return new_regression_df, vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77e6186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_regression_df(dataframe: pd.DataFrame, decades: list,\n",
    "                         parameters=DEFAULT_PARAMETERS, target_threshold=8) -> tuple:\n",
    "    \"\"\"\n",
    "    Process the dataframe for regression and creates targets and weights vectors.\n",
    "    \n",
    "    :param dataframe: Pandas DataFrame containing the data for regression.\n",
    "    :param decades: List of decades to integrate for regression. \n",
    "                    If empty then all decades will be considered.\n",
    "    :param parameters: Parameter dictionnary to process the dataframe.\n",
    "    :param target_threshold: Threshold from which we consider a movie as successful.\n",
    "      \n",
    "    :return: Tuple with the regression DataFrame, the raw and binary targets and the number of votes.\n",
    "    \"\"\"\n",
    "    parameters[\"decades\"] = decades\n",
    "    processed_df = process_dataframe(dataframe,parameters)\n",
    "    # Extract target and associated features.\n",
    "    target, num_votes= processed_df[\"average_rating\"], processed_df[\"num_votes\"]\n",
    "    binary_target = target.copy()\n",
    "    binary_target[binary_target<target_threshold] = 0\n",
    "    binary_target[binary_target>=target_threshold] = 1\n",
    "    # Remove Unecessary Columns.\n",
    "    processed_df = processed_df.drop([\"release_date\",\"num_votes\",\n",
    "                                \"runtime\",\"has_common_language\",\"language_number\",\n",
    "                                \"decade\",\"average_rating\",\"combinned_best_rating\"],axis=1)\n",
    "    processed_df, vif_df = filter_multicolinearity(processed_df)\n",
    "    return processed_df, target, binary_target, num_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7ffcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df, target, binary_target, num_votes = format_regression_df(movie_regression_df,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f58d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = forward_selection(processed_df, target, ignored_features=[], alpha=0.05, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2ed6640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(target, sm.add_constant(processed_df[features])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dab1f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>average_rating</td>  <th>  R-squared:         </th> <td>   0.164</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   201.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 16 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:05:58</td>     <th>  Log-Likelihood:    </th> <td> -24472.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 18482</td>      <th>  AIC:               </th> <td>4.898e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 18463</td>      <th>  BIC:               </th> <td>4.913e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                     <td>    5.8532</td> <td>    0.020</td> <td>  293.682</td> <td> 0.000</td> <td>    5.814</td> <td>    5.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>combinned_movie_success</th>   <td>    0.4828</td> <td>    0.015</td> <td>   32.604</td> <td> 0.000</td> <td>    0.454</td> <td>    0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drama</th>                     <td>    0.3198</td> <td>    0.015</td> <td>   20.836</td> <td> 0.000</td> <td>    0.290</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horror</th>                    <td>   -0.3333</td> <td>    0.027</td> <td>  -12.172</td> <td> 0.000</td> <td>   -0.387</td> <td>   -0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Western Europe</th>            <td>    0.1627</td> <td>    0.016</td> <td>   10.298</td> <td> 0.000</td> <td>    0.132</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>animation</th>                 <td>    0.5907</td> <td>    0.054</td> <td>   10.893</td> <td> 0.000</td> <td>    0.484</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fantasy</th>                   <td>   -0.2257</td> <td>    0.024</td> <td>   -9.358</td> <td> 0.000</td> <td>   -0.273</td> <td>   -0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_number</th>              <td>    0.0148</td> <td>    0.001</td> <td>   11.703</td> <td> 0.000</td> <td>    0.012</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Eastern Europe and Russia</th> <td>    0.3215</td> <td>    0.045</td> <td>    7.199</td> <td> 0.000</td> <td>    0.234</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Asia</th>                      <td>    0.1356</td> <td>    0.019</td> <td>    7.093</td> <td> 0.000</td> <td>    0.098</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adult</th>                     <td>   -0.4303</td> <td>    0.061</td> <td>   -7.082</td> <td> 0.000</td> <td>   -0.549</td> <td>   -0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>action</th>                    <td>   -0.0972</td> <td>    0.020</td> <td>   -4.918</td> <td> 0.000</td> <td>   -0.136</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>children</th>                  <td>   -0.1515</td> <td>    0.028</td> <td>   -5.468</td> <td> 0.000</td> <td>   -0.206</td> <td>   -0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>comedy</th>                    <td>   -0.0986</td> <td>    0.016</td> <td>   -6.300</td> <td> 0.000</td> <td>   -0.129</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre</th>                     <td>    0.1294</td> <td>    0.022</td> <td>    5.848</td> <td> 0.000</td> <td>    0.086</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_ratio</th>              <td>   -0.0854</td> <td>    0.017</td> <td>   -4.937</td> <td> 0.000</td> <td>   -0.119</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adventure</th>                 <td>   -0.0654</td> <td>    0.021</td> <td>   -3.099</td> <td> 0.002</td> <td>   -0.107</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thriller</th>                  <td>   -0.0425</td> <td>    0.016</td> <td>   -2.705</td> <td> 0.007</td> <td>   -0.073</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_length</th>              <td>    0.0169</td> <td>    0.007</td> <td>    2.477</td> <td> 0.013</td> <td>    0.004</td> <td>    0.030</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2191.820</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3803.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.528</td>  <th>  Cond. No.          </th> <td>    98.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         average_rating   R-squared:                       0.164\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     201.9\n",
       "Date:                Fri, 16 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        11:05:58   Log-Likelihood:                -24472.\n",
       "No. Observations:               18482   AIC:                         4.898e+04\n",
       "Df Residuals:                   18463   BIC:                         4.913e+04\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================\n",
       "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "const                         5.8532      0.020    293.682      0.000       5.814       5.892\n",
       "combinned_movie_success       0.4828      0.015     32.604      0.000       0.454       0.512\n",
       "drama                         0.3198      0.015     20.836      0.000       0.290       0.350\n",
       "horror                       -0.3333      0.027    -12.172      0.000      -0.387      -0.280\n",
       "Western Europe                0.1627      0.016     10.298      0.000       0.132       0.194\n",
       "animation                     0.5907      0.054     10.893      0.000       0.484       0.697\n",
       "fantasy                      -0.2257      0.024     -9.358      0.000      -0.273      -0.178\n",
       "actor_number                  0.0148      0.001     11.703      0.000       0.012       0.017\n",
       "Eastern Europe and Russia     0.3215      0.045      7.199      0.000       0.234       0.409\n",
       "Asia                          0.1356      0.019      7.093      0.000       0.098       0.173\n",
       "adult                        -0.4303      0.061     -7.082      0.000      -0.549      -0.311\n",
       "action                       -0.0972      0.020     -4.918      0.000      -0.136      -0.058\n",
       "children                     -0.1515      0.028     -5.468      0.000      -0.206      -0.097\n",
       "comedy                       -0.0986      0.016     -6.300      0.000      -0.129      -0.068\n",
       "genre                         0.1294      0.022      5.848      0.000       0.086       0.173\n",
       "gender_ratio                 -0.0854      0.017     -4.937      0.000      -0.119      -0.052\n",
       "adventure                    -0.0654      0.021     -3.099      0.002      -0.107      -0.024\n",
       "thriller                     -0.0425      0.016     -2.705      0.007      -0.073      -0.012\n",
       "title_length                  0.0169      0.007      2.477      0.013       0.004       0.030\n",
       "==============================================================================\n",
       "Omnibus:                     2191.820   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3803.930\n",
       "Skew:                          -0.807   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.528   Cond. No.                         98.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26ce4e",
   "metadata": {},
   "source": [
    "## Decade pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_results = dict()\n",
    "for decade in movie_regression_df[\"decade\"].value_counts().head(11).index:\n",
    "    processed_df, target, binary_target, num_votes = format_regression_df(movie_regression_df,[decade])\n",
    "    features = forward_selection(processed_df, target, ignored_features=[], alpha=0.05, show=False)\n",
    "    model = sm.OLS(target, sm.add_constant(processed_df)).fit()\n",
    "    decade_results[decade] = model.rsquared\n",
    "decade_results_df = pd.DataFrame(decade_results.values(),index=decade_results.keys(),\n",
    "                                columns=[\"r-squared\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58b4c1",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba217a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = sm.GLM(binary_target, sm.add_constant(process_df[current_features]),\n",
    "               family=sm.families.Binomial(link=sm.families.links.logit())).fit_regularized(\n",
    "                alpha=0.001,L1_wt=0)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(binary_target, sm.add_constant(process_df)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e78e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = binary_target[model.predict(sm.add_constant(process_df)) > 0.5].sum()\n",
    "print(f\"The Logistic Regression models with all features gives us {tp:.0f} true positives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf1764",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4e325",
   "metadata": {},
   "source": [
    "### Weighted Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eda3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_num_votes = np.log(num_votes)\n",
    "weights = 1+(log_num_votes-log_num_votes.min())/(log_num_votes.max()-log_num_votes.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25169be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(process_df, target,\n",
    "         weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5da75d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492bc01",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4294f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e401f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = process_df.copy()\n",
    "tmp_df[\"target\"] = binary_target.copy()\n",
    "train, test = train_test_split(tmp_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2041a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "_ = clf.fit(train.drop(\"target\",axis=1), train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test.drop(\"target\",axis=1))\n",
    "score = metrics.f1_score(test[\"target\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e92e1",
   "metadata": {},
   "source": [
    "## Advanced Tasks\n",
    "\n",
    "- Compute centrality of directors and actors instead of #movies\n",
    "- Subset on plot and extract NLP features --> odds ratio of terms / LDA and topic association (decorelation with genre)\n",
    "- Matrix factorization for value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95125fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b2c13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "B.add_nodes_from(set(appears_in_df[\"actor_id\"]), bipartite=0)\n",
    "B.add_nodes_from(set(appears_in_df[\"movie_id\"]), bipartite=1)\n",
    "actor_movie_edges = list(zip(appears_in_df[\"actor_id\"],appears_in_df[\"movie_id\"]))\n",
    "B.add_edges_from(actor_movie_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9166ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_nodes = {n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "movie_nodes = set(B) - top_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de2818bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_graph = nx.projected_graph(B,actor_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38a8560e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m actor_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mharmonic_centrality(actor_graph,actor_nodes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\networkx\\algorithms\\centrality\\harmonic.py:72\u001b[0m, in \u001b[0;36mharmonic_centrality\u001b[1;34m(G, nbunch, distance, sources)\u001b[0m\n\u001b[0;32m     70\u001b[0m centrality \u001b[38;5;241m=\u001b[39m {u: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m nbunch}\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m sources:\n\u001b[1;32m---> 72\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mspl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m nbunch\u001b[38;5;241m.\u001b[39mintersection(dist):\n\u001b[0;32m     74\u001b[0m         d \u001b[38;5;241m=\u001b[39m dist[u]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\generic.py:297\u001b[0m, in \u001b[0;36mshortest_path_length\u001b[1;34m(G, source, target, weight, method)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m# Find paths to all nodes accessible from the source.\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m         paths \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_source_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdijkstra\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m         path_length \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39msingle_source_dijkstra_path_length\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py:59\u001b[0m, in \u001b[0;36msingle_source_shortest_path_length\u001b[1;34m(G, source, cutoff)\u001b[0m\n\u001b[0;32m     57\u001b[0m     cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m nextlevel \u001b[38;5;241m=\u001b[39m {source: \u001b[38;5;241m1\u001b[39m}\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_single_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnextlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py:91\u001b[0m, in \u001b[0;36m_single_shortest_path_length\u001b[1;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m found:\n\u001b[1;32m---> 91\u001b[0m         nextlevel\u001b[38;5;241m.\u001b[39mupdate(adj[v])\n\u001b[0;32m     92\u001b[0m     level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m seen\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actor_centrality = nx.harmonic_centrality(actor_graph,actor_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ad415ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decade\n",
       "1890       1\n",
       "1900       5\n",
       "1910     124\n",
       "1920     432\n",
       "1930    1340\n",
       "1940    1503\n",
       "1950    1851\n",
       "1960    1858\n",
       "1970    2122\n",
       "1980    2973\n",
       "1990    3995\n",
       "2000    7791\n",
       "2010    2292\n",
       "2020       0\n",
       "Name: plot, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.merge(movie_regression_df[\"decade\"],on=\"movie_id\",how=\"left\").groupby(\"decade\")[\"plot\"].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
